{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AF Data Science Project\n",
    "__Author: Fan Yuan__  \n",
    "__Created: 07/28/2019__  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Description\n",
    "\n",
    "In this project we analyze a U.S. census data taken from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Census+Income). The goal of this project is to profile people in the above dataset based on available demographic attributes.\n",
    "\n",
    "1) Construct a model that accurately predicts whether an individual makes more than $50,000.  \n",
    "2) What are the key factors contributing to high vs. low income?  \n",
    "3) Are there any significant gaps in these Census attributes by gender or race?  \n",
    "4) Any underneath clusters (group) based on census data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Data Information__  \n",
    "`age`: continuous.  \n",
    "`workclass`: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked.  \n",
    "`fnlwgt`: final weight, continuous.  \n",
    "`education`: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool.  \n",
    "`education-num`:  continuous.  \n",
    "`marital-status`: Represents the responding unit’s role in the family. Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse.  \n",
    "`occupation`: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces.  \n",
    "`relationship`: Represents the responding unit’s role in the family. Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried.  \n",
    "`race`: White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black.  \n",
    "`sex`: Female, Male.  \n",
    "`capital-gain`: income from investment sources, apart from wages/salary, continuous.  \n",
    "`capital-loss`: losses from investment sources, apart from wages/salary, continuous.  \n",
    "`hours-per-week`: continuous.  \n",
    "`native-country`: United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Data\n",
    "\n",
    "### Load necessry Python libraries and the census data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries necessary for this project\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\")\n",
    "from time import time\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Import 'GridSearchCV', 'make_scorer', and any other necessary libraries\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Import the three supervised learning models from sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA    \n",
    "\n",
    "# Pretty display for notebooks\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'adult.data' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-5832508f8b27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Read in train data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0madult_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'adult.data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipinitialspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Drop the fnlwgt column which is useless for later analysis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1708\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'adult.data' does not exist"
     ]
    }
   ],
   "source": [
    "# Add column names to data set\n",
    "columns = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', \n",
    "           'relationship', 'race','sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income']\n",
    "\n",
    "# Read in train data\n",
    "adult_train = pd.read_csv('adult.data', header=None, names=columns, skipinitialspace=True)\n",
    "\n",
    "# Drop the fnlwgt column which is useless for later analysis\n",
    "adult_train = adult_train.drop('fnlwgt', axis=1)\n",
    "\n",
    "# Display several rows and shape of data set\n",
    "display(adult_train.head())\n",
    "display(adult_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'adult.test' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-a87c983ae84c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Read in test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0madult_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'adult.test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskiprows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipinitialspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Drop the fnlwgt column which is useless for later analysis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0madult_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madult_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fnlwgt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1708\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'adult.test' does not exist"
     ]
    }
   ],
   "source": [
    "# Read in test data\n",
    "adult_test = pd.read_csv('adult.test', header=None, skiprows=1, names=columns, skipinitialspace=True)\n",
    "\n",
    "# Drop the fnlwgt column which is useless for later analysis\n",
    "adult_test = adult_test.drop('fnlwgt', axis=1)\n",
    "\n",
    "# Remove '.' in income column\n",
    "adult_test['income'] = adult_test['income'].apply(lambda x: '>50K' if x=='>50K.' else '<=50K')\n",
    "\n",
    "# Review several rows and shape of data set\n",
    "display(adult_test.head())\n",
    "display(adult_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing missing data\n",
    "Have a quick check on whether there's any huge missing value in columns or rows which may largely affect later analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'adult_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-9001aaee0cb0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Examine if there are missing value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0madult_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'adult_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Examine if there are missing value\n",
    "adult_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process unknown/missing data\n",
    "The result above shows there's no `null` value in dataset. But according to data notes provided, unknown data was converted into '?'. Therefore, next we'll convert '?' to NaNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'adult_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-9eba268ae817>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Check missing value code and convert to NaNs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mobject_col\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madult_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_dtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobject_col\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madult_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0madult_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'adult_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Check missing value code and convert to NaNs\n",
    "object_col = adult_train.select_dtypes(include=object).columns.tolist()\n",
    "for col in object_col:\n",
    "    print(adult_train[col].value_counts(dropna=False)/adult_train.shape[0],'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the missing data '?' is in a small volumn, here I choose to just remove the unknown data which flagged as '?' here. But if the missing data is in a large volumn, need to consider imputing NaNs with more advanced methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'object_col' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-b2514fb8292e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Convert '?' to NaNs and remove the entries with NaN value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobject_col\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0madult_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0madult_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'?'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0madult_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0madult_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'?'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'object_col' is not defined"
     ]
    }
   ],
   "source": [
    "# Convert '?' to NaNs and remove the entries with NaN value\n",
    "for col in object_col:\n",
    "    adult_train.loc[adult_train[col]=='?', col] = np.nan\n",
    "    adult_test.loc[adult_test[col]=='?', col] = np.nan\n",
    "\n",
    "# Perform an mssing assessment in each column of the dataset.\n",
    "col_missing_pct = adult_train.isna().sum()/adult_train.shape[0]\n",
    "col_missing_pct.sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The largest missing percentage by column level is 5% in dataset, and most columns are complete enough. Therefore, here I'll remove the NaN values instead of manually imputing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'adult_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-4a39930db5a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Remove data entries with missing value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0madult_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madult_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'any'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0madult_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madult_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'any'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Show the results of the split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'adult_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Remove data entries with missing value\n",
    "adult_train = adult_train.dropna(axis=0, how='any')\n",
    "adult_test = adult_test.dropna(axis=0, how='any')\n",
    "\n",
    "# Show the results of the split\n",
    "print(\"After removing the missing value:\")\n",
    "print(\"Training set has {} samples.\".format(adult_train.shape[0]))\n",
    "print(\"Testing set has {} samples.\".format(adult_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial review on data set\n",
    "\n",
    "The goal is to identify if an individual has an income over 50k or not, so first have an overlook at how the income ditributes in the data set. A cursory investigation of the dataset will determine how many individuals fit into either group, and will tell us about the percentage of these individuals making more than \\$50,000. \n",
    "\n",
    "Here I'll generate some variables to help analysis as below:\n",
    "- The total number of records, `'n_records'`\n",
    "- The number of individuals making more than \\$50,000 annually, `'n_greater_50k'`.\n",
    "- The number of individuals making at most \\$50,000 annually, `'n_at_most_50k'`.\n",
    "- The percentage of individuals making more than \\$50,000 annually, `'greater_percent'`.\n",
    "\n",
    "__Note:__\n",
    "Since in EDA process, we don't need the test data, I'll combine the train and test data in this section just for getting a better and more general distribution of data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'adult_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-7faa724ea534>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Combine the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0madult_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0madult_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madult_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'adult_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Combine the data\n",
    "adult_data = pd.concat([adult_train, adult_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'adult_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-638adb271b93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Overview of the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'income'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'capital-gain'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sex'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madult_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bar'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'race'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relationship'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'adult_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Overview of the data\n",
    "sns.catplot('income', 'capital-gain', hue='sex', data=adult_data, kind='bar', col='race', row='relationship')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'adult_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-0d9528cc2e4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Initiate plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcountplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'age'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'income'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madult_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0madult_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msex\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'Female'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaturation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcountplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'age'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'income'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madult_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0madult_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msex\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'Male'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaturation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'adult_data' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfAAAAK0CAYAAAD8jW8BAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3W+IpXd5//HPzMaIuFsq0wkkMTb9t18oTQrbpCJUpWha65NKq7VLaaBCS55ssdAHRaoEpVCoYJGuJE1LSWu7ldoSoaS/gPjAWihaTOqf1itBo4mJNsMgIakYcHd+D+asnWzGnXtmzzmTa/f1grCZ2+8MFxebfe99zvGcla2trQAAvawe9gAAwP4JOAA0JOAA0JCAA0BDAg4ADQk4ADQk4ADQkIADQENX7XVgjPH+JL+a5MYkN1XVF3Y5cyTJB5O8KclWkj+uqr+Y76gAwHlT7sDvS/K6JF+7yJnfSPLjSX4iyWuS3DnGuPGSpwMAdrVnwKvqU1X1+B7H3p7knqo6V1Ub2Y7+2+YxIADwQns+hD7Rq/L8O/THktywj+9/aZJbk3wjydk5zQQAL1ZHklyb5DNJnjvID5hXwC/VrUn+9bCHAIAle22STx3kG+cV8MeS/HC2/yaRvPCOfC/fSJJvfet/c+6cT0dblLW1o9ncfPawx7js2fPi2fHi2fFira6u5BWveHky699BzCvg/5Dkt8cY/5RkLclbsv3Ct6nOJsm5c1sCvmD2uxz2vHh2vHh2vBQHftp4zxexjTE+OMb4epJXJvn4GOOLs+v3jzFumR37myRfSfJIkn9P8t6q+spBhwIALm5la+tF8TesG5M8urn5rL/xLdD6+rFsbDxz2GNc9ux58ex48ex4sVZXV7K2djRJfiTJVw/0M+Y5EACwHAIOAA0JOAA0JOAA0JCAA0BDAg4ADQk4ADQk4ADQkIADQEMCDgANCTgANCTgANCQgANAQwIOAA0JOAA0JOAA0JCAA0BDAg4ADQk4ADQk4ADQkIADQEMCDgANCTgANCTgANCQgANAQwIOAA0JOAA0JOAA0JCAA0BDAg4ADQk4ADQk4ADQkIADQEMCDgANCTgANCTgANCQgANAQwIOAA0JOAA0JOAA0JCAA0BDAg4ADQk4ADQk4ADQkIADQEMCDgANCTgANCTgANCQgANAQwIOAA0JOAA0dNWUQ2OM40nuTbKWZDPJ7VX1yAVnrknyV0luSHJ1kk8k+d2q+u5cJwYAJt+B35XkdFUdT3I6yd27nHlXkv+uqpuT3JTkZ5L8ylymBACeZ8+Az+6sTyQ5M7t0JsmJMcb6BUe3khwbY6wmeWm278KfmOOsAMDMlIfQb0jyRFWdTZKqOjvGeHJ2fWPHufcl+cck30jy8iR/VlX/tp9h1taO7uc4B7C+fuywR7gi2PPi2fHi2fGL26TnwCd6W5LPJXlDkmNJ/mWM8daq+ujUH7C5+WzOndua40jstL5+LBsbzxz2GJc9e148O148O16s1dWVS75pnfIc+ONJrh9jHEmS2a/Xza7vdCrJ31bVuap6OsnHkvz8JU0HAOxqz4BX1VNJHkpycnbpZJIHq2rjgqOPJnlTkowxrk7yxiRfmN+oAMB5U1+FfkeSU2OMh7N9p31Hkowx7h9j3DI7884krx1jfD7bwX84yT1znhcAyMTnwKvqS0levcv1N+/49y8nuW1+owEA3493YgOAhgQcABoScABoSMABoCEBB4CGBBwAGhJwAGhIwAGgIQEHgIYEHAAaEnAAaEjAAaAhAQeAhgQcABoScABoSMABoCEBB4CGBBwAGhJwAGhIwAGgIQEHgIYEHAAaEnAAaEjAAaAhAQeAhgQcABoScABoSMABoCEBB4CGBBwAGhJwAGhIwAGgIQEHgIYEHAAaEnAAaEjAAaAhAQeAhgQcABoScABoSMABoCEBB4CGBBwAGhJwAGhIwAGgIQEHgIYEHAAaEnAAaEjAAaAhAQeAhgQcABq6asqhMcbxJPcmWUuymeT2qnpkl3O/luTdSVaSbCV5Y1X9z/zGBQCS6XfgdyU5XVXHk5xOcveFB8YYtyS5M8ltVfVTSX4uydNzmhMA2GHPgI8xrklyIsmZ2aUzSU6MMdYvOPp7Sd5fVd9Mkqp6uqq+M89hAYBtUx5CvyHJE1V1Nkmq6uwY48nZ9Y0d534yyaNjjE8mOZrkn5L8UVVtzXlmALjiTXoOfB8/6+YktyW5Osn/S/JYkr+e+gPW1o7OcRx2s75+7LBHuCLY8+LZ8eLZ8YvblIA/nuT6McaR2d33kSTXza7v9LUkH62q55I8N8b4WJKfzT4Cvrn5bM6dc8O+KOvrx7Kx8cxhj3HZs+fFs+PFs+PFWl1dueSb1j2fA6+qp5I8lOTk7NLJJA9W1cYFR/8uyS+MMVbGGC9J8oYk/3lJ0wEAu5r6KvQ7kpwaYzyc5NTs64wx7p+9+jxJ/j7JU0n+K9vB/2KSv5zvuABAkqxsbb0oHrK+McmjHkJfLA+JLYc9L54dL54dL9aOh9B/JMlXD/Qz5jkQALAcAg4ADQk4ADQk4ADQkIADQEMCDgANCTgANCTgANCQgANAQwIOAA0JOAA0JOAA0JCAA0BDAg4ADQk4ADQk4ADQkIADQEMCDgANCTgANCTgANCQgANAQwIOAA0JOAA0JOAA0JCAA0BDAg4ADQk4ADQk4ADQkIADQEMCDgANCTgANCTgANCQgANAQwIOAA0JOAA0JOAA0JCAA0BDAg4ADQk4ADQk4ADQkIADQEMCDgANCTgANCTgANCQgANAQwIOAA0JOAA0JOAA0JCAA0BDAg4ADV015dAY43iSe5OsJdlMcntVPfJ9zo4kDyb5UFX9/rwGBQD+z9Q78LuSnK6q40lOJ7l7t0NjjCOz/+2++YwHAOxmz4CPMa5JciLJmdmlM0lOjDHWdzn+B0n+OcnDc5sQAHiBKXfgNyR5oqrOJsns1ydn179njHFzkl9M8oF5DwkAPN+k58D3MsZ4SZJ7kvxWVZ3dfhp8/9bWjs5jHC5iff3YYY9wRbDnxbPjxbPjF7cpAX88yfVjjCOzOB9Jct3s+nnXJvmxJPfP4v2DSVbGGD9QVb8zdZjNzWdz7tzW9OnZl/X1Y9nYeOawx7js2fPi2fHi2fFira6uXPJN654Br6qnxhgPJTmZ5MOzXx+sqo0dZx5L8kPnvx5j3JnkqFehA8BiTH0V+h1JTo0xHk5yavZ1xhj3jzFuWdRwAMDuJj0HXlVfSvLqXa6/+fucv/PSxgIALsY7sQFAQwIOAA0JOAA0JOAA0JCAA0BDAg4ADQk4ADQk4ADQkIADQEMCDgANCTgANCTgANCQgANAQwIOAA0JOAA0JOAA0JCAA0BDAg4ADQk4ADQk4ADQkIADQEMCDgANCTgANCTgANCQgANAQwIOAA0JOAA0JOAA0JCAA0BDAg4ADQk4ADQk4ADQkIADQEMCDgANCTgANCTgANCQgANAQwIOAA0JOAA0JOAA0JCAA0BDAg4ADQk4ADQk4ADQkIADQEMCDgANCTgANCTgANCQgANAQwIOAA1dNeXQGON4knuTrCXZTHJ7VT1ywZl3J/n1JN+d/fOuqnpgvuMCAMn0O/C7kpyuquNJTie5e5czn05ya1X9dJJ3JPnIGONl8xkTANhpz4CPMa5JciLJmdmlM0lOjDHWd56rqgeq6tuzLz+XZCXbd+wAwJxNuQO/IckTVXU2SWa/Pjm7/v3cnuTLVfX1Sx8RALjQpOfA92OM8fok70ty236/d23t6LzH4QLr68cOe4Qrgj0vnh0vnh2/uE0J+ONJrh9jHKmqs2OMI0mum11/njHGa5J8OMkvV1Xtd5jNzWdz7tzWfr+NidbXj2Vj45nDHuOyZ8+LZ8eLZ8eLtbq6csk3rXs+hF5VTyV5KMnJ2aWTSR6sqo2d58YYtyb5SJK3VtVnL2kqAOCipj6EfkeSe8cY70nyrWw/x50xxv1J3lNV/5HkQ0leluTuMcb57/vNqvr8fEcGACYFvKq+lOTVu1x/845/v3WOcwEAF+Gd2ACgIQEHgIYEHAAaEnAAaEjAAaAhAQeAhgQcABoScABoSMABoCEBB4CGBBwAGhJwAGhIwAGgIQEHgIYEHAAaEnAAaEjAAaAhAQeAhgQcABoScABoSMABoCEBB4CGBBwAGhJwAGhIwAGgIQEHgIYEHAAaEnAAaEjAAaAhAQeAhgQcABoScABoSMABoCEBB4CGBBwAGhJwAGhIwAGgIQEHgIYEHAAaEnAAaEjAAaAhAQeAhgQcABoScABoSMABoCEBB4CGBBwAGhJwAGhIwAGgIQEHgIYEHAAaumrKoTHG8ST3JllLspnk9qp65IIzR5J8MMmbkmwl+eOq+ov5jgsAJNPvwO9Kcrqqjic5neTuXc78RpIfT/ITSV6T5M4xxo3zGBIAeL4978DHGNckOZHkttmlM0n+bIyxXlUbO46+Pck9VXUuycYY474kb0vyJxPmOJIkq6sr+5mdA7Dj5bDnxbPjxbPjxdmx2yMH/RlTHkK/IckTVXU2Sarq7Bjjydn1nQF/VZKv7fj6sdmZKa5Nkle84uUTj3NQa2tHD3uEK4I9L54dL54dL8W1Sb58kG+c9Bz4EnwmyWuTfCPJ2UOeBQAW7Ui24/2Zg/6AKQF/PMn1Y4wjs7vvI0mum13f6bEkP7xjmAvvyC/muSSfmngWAC4HB7rzPm/PF7FV1VNJHkpycnbpZJIHL3j+O0n+IclvjzFWxxjrSd6S5B8vZTgAYHdTX4V+R5JTY4yHk5yafZ0xxv1jjFtmZ/4myVeSPJLk35O8t6q+Mud5AYAkK1tbW4c9AwCwT96JDQAaEnAAaEjAAaAhAQeAhpb6Ri4+FGXxJu743Ul+Pcl3Z/+8q6oeWPasnU3Z846zI8mDST5UVb+/vCl7m7rjMcavJXl3kpVs/5nxxqr6n2XO2tXEPy+uSfJX2X5nzauTfCLJ71bVd5c8bktjjPcn+dUkNya5qaq+sMuZA3Vv2XfgPhRl8abs+NNJbq2qn07yjiQfGWO8bIkzXg6m7Pn8f5h3J7lvibNdLvbc8ez/xnpnktuq6qeS/FySp5c5ZHNTfh+/K8l/V9XNSW5K8jNJfmV5I7Z3X5LX5eJvbHag7i0t4Ds+FOXM7NKZJCdmb/qy0/c+FGX2ZjHnPxSFPUzdcVU9UFXfnn35uWzfuawtbdDm9vF7OUn+IMk/J3l4SeNdFvax499L8v6q+maSVNXTVfWd5U3a1z52vJXk2BhjNclLs30X/sTSBm2uqj5VVRe+c+mFDtS9Zd6Bv+BDUZKc/1CUnS7lQ1GudFN3vNPtSb5cVV9fwnyXi0l7HmPcnOQXk3xg6RP2N/X38k8m+dExxifHGJ8dY/zhGMNHaE0zdcfvS3I8259V8c0kD1TVvy1z0CvAgbrnRWxXsDHG67P9H+fJvc6yP2OMlyS5J8kd5/+AZCGuSnJztj/u+PVJfinJbx7qRJeft2X7kbprk1yf5HVjjLce7kgkyw349z4UJfnec4MX+1CU8161yxl2N3XHGWO8JsmHk7ylqmqpU/Y3Zc/XJvmxJPePMb6a5J3Z/qyAP1/uqG1N/b38tSQfrarnquqZJB9L8rNLnbSvqTs+leRvZw/vPp3tHf/8Uie9/B2oe0sLuA9FWbypOx5j3JrkI0neWlWfXe6U/U3Zc1U9VlU/VFU3VtWNSf40289x/c7SB25oH39e/F2SXxhjrMwe9XhDkv9c3qR97WPHj2b71dEZY1yd5I1JXvBKai7Jgbq37IfQfSjK4k3Z8YeSvCzJ3WOMh2b/3HQ447Y1Zc9cmik7/vskTyX5r2zH6ItJ/vIQZu1qyo7fmeS1Y4zPZ3vHD2f76SEmGGN8cIzx9SSvTPLxMcYXZ9cvuXs+zAQAGvIiNgBoSMABoCEBB4CGBBwAGhJwAGhIwAGgIQEHgIYEHAAaEnAAaEjAAaAhAQeAhgQcABoScABoSMABoCEBB4CGBBwAGhJwAGhIwAGgIQEHgIYEHAAaEnAAaEjAAaAhAQeAhgQcABoScABoSMABoCEBB4CGBBwAGhJwAGhIwAGgIQEHgIYEHAAaEnAAaEjAAaAhAQeAhgQcABoScABo6Kq9Dowx3p/kV5PcmOSmqvrCLmeOJPlgkjcl2Uryx1X1F/MdFQA4b8od+H1JXpfkaxc58xtJfjzJTyR5TZI7xxg3XvJ0AMCu9gx4VX2qqh7f49jbk9xTVeeqaiPb0X/bPAYEAF5oz4fQJ3pVnn+H/liSG/bx/S9NcmuSbyQ5O6eZAODF6kiSa5N8JslzB/kB8wr4pbo1yb8e9hAAsGSvTfKpg3zjvAL+WJIfzvbfJJIX3pHv5RtJ8q1v/W/Ondua00hcaG3taDY3nz3sMS579rx4drx4drxYq6srecUrXp7M+ncQ8wr4PyT57THGPyVZS/KWbL/wbaqzSXLu3JaAL5j9Loc9L54dL54dL8WBnzbe80VsY4wPjjG+nuSVST4+xvji7Pr9Y4xbZsf+JslXkjyS5N+TvLeqvnLQoQCAi1vZ2npR/A3rxiSPbm4+6298C7S+fiwbG88c9hiXPXtePDtePDterNXVlaytHU2SH0ny1QP9jHkOBAAsh4ADQEMCDgANCTgANCTgANCQgANAQwIOAA0JOAA0JOAA0JCAA0BDAg4ADQk4ADQk4ADQkIADQEMCDgANCTgANCTgANCQgANAQwIOAA0JOAA0JOAA0JCAA0BDAg4ADQk4ADQk4ADQkIADQEMCDgANCTgANCTgANCQgANAQwIOAA0JOAA0JOAA0JCAA0BDAg4ADQk4ADQk4ADQkIADQEMCDgANCTgANCTgANCQgANAQwIOAA0JOAA0JOAA0JCAA0BDAg4ADQk4ADQk4ADQkIADQENXTTk0xjie5N4ka0k2k9xeVY9ccOaaJH+V5IYkVyf5RJLfrarvznViAGDyHfhdSU5X1fEkp5PcvcuZdyX576q6OclNSX4mya/MZUoA4Hn2DPjszvpEkjOzS2eSnBhjrF9wdCvJsTHGapKXZvsu/Ik5zgoAzEy5A78hyRNVdTZJZr8+Obu+0/uSHE/yjSTfTPJAVf3bHGcFAGYmPQc+0duSfC7JG5IcS/IvY4y3VtVHp/6AtbWjcxyH3ayvHzvsEa4I9rx4drx4dvziNiXgjye5foxxpKrOjjGOJLludn2nU0neUVXnkjw9xvhYkp9PMjngm5vP5ty5ranH2af19WPZ2HjmsMe47Nnz4tnx4tnxYq2urlzyTeueD6FX1VNJHkpycnbpZJIHq2rjgqOPJnlTkowxrk7yxiRfuKTpAIBdTX0V+h1JTo0xHs72nfYdSTLGuH+MccvszDuTvHaM8flsB//hJPfMeV4AIBOfA6+qLyV59S7X37zj37+c5Lb5jQYAfD/eiQ0AGhJwAGhIwAGgIQEHgIYEHAAaEnAAaEjAAaAhAQeAhgQcABoScABoSMABoCEBB4CGBBwAGhJwAGhIwAGgIQEHgIYEHAAaEnAAaEjAAaAhAQeAhgQcABoScABoSMABoCEBB4CGBBwAGhJwAGhIwAGgIQEHgIYEHAAaEnAAaEjAAaAhAQeAhgQcABoScABoSMABoCEBB4CGBBwAGhJwAGhIwAGgIQEHgIYEHAAaEnAAaEjAAaAhAQeAhgQcABoScABoSMABoCEBB4CGBBwAGhJwAGhIwAGgoaumHBpjHE9yb5K1JJtJbq+qR3Y592tJ3p1kJclWkjdW1f/Mb1wAIJl+B35XktNVdTzJ6SR3X3hgjHFLkjuT3FZVP5Xk55I8Pac5AYAd9gz4GOOaJCeSnJldOpPkxBhj/YKjv5fk/VX1zSSpqqer6jvzHBYA2DblIfQbkjxRVWeTpKrOjjGenF3f2HHuJ5M8Osb4ZJKjSf4pyR9V1dbUYdbWjk4enINZXz922CNcEex58ex48ez4xW3Sc+D7+Fk3J7ktydVJ/l+Sx5L89dQfsLn5bM6dm9x79ml9/Vg2Np457DEue/a8eHa8eHa8WKurK5d80zrlOfDHk1w/xjiSJLNfr5td3+lrST5aVc9V1TNJPpbkZy9pOgBgV3sGvKqeSvJQkpOzSyeTPFhVGxcc/bskvzDGWBljvCTJG5L85zyHBQC2TX0V+h1JTo0xHk5yavZ1xhj3z159niR/n+SpJP+V7eB/MclfzndcACBJVra2XhTPOd+Y5FHPgS+W57SWw54Xz44Xz44Xa8dz4D+S5KsH+hnzHAgAWA4BB4CGBBwAGhJwAGhIwAGgIQEHgIYEHAAaEnAAaEjAAaAhAQeAhgQcABoScABoSMABoCEBB4CGBBwAGhJwAGhIwAGgIQEHgIYEHAAaEnAAaEjAAaAhAQeAhgQcABoScABoSMABoCEBB4CGBBwAGhJwAGhIwAGgIQEHgIYEHAAaEnAAaEjAAaAhAQeAhgQcABoScABoSMABoCEBB4CGBBwAGhJwAGhIwAGgIQEHgIYEHAAaEnAAaEjAAaAhAQeAhgQcABoScABoSMABoCEBB4CGrppyaIxxPMm9SdaSbCa5vaoe+T5nR5IHk3yoqn5/XoMCAP9n6h34XUlOV9XxJKeT3L3boTHGkdn/dt98xgMAdrNnwMcY1yQ5keTM7NKZJCfGGOu7HP+DJP+c5OG5TQgAvMCUO/AbkjxRVWeTZPbrk7Pr3zPGuDnJLyb5wLyHBACeb9Jz4HsZY7wkyT1Jfquqzm4/Db5/a2tH5zEOF7G+fuywR7gi2PPi2fHi2fGL25SAP57k+jHGkVmcjyS5bnb9vGuT/FiS+2fx/sEkK2OMH6iq35k6zObmszl3bmv69OzL+vqxbGw8c9hjXPbsefHsePHseLFWV1cu+aZ1z4BX1VNjjIeSnEzy4dmvD1bVxo4zjyX5ofNfjzHuTHLUq9ABYDGmvgr9jiSnxhgPJzk1+zpjjPvHGLcsajgAYHeTngOvqi8lefUu19/8fc7feWljAQAX453YAKAhAQeAhgQcABoScABoSMABoCEBB4CGBBwAGhJwAGhIwAGgIQEHgIYEHAAaEnAAaEjAAaAhAQeAhgQcABoScABoSMABoCEBB4CGBBwAGhJwAGhIwAGgIQEHgIYEHAAaEnAAaEjAAaAhAQeAhgQcABoScABoSMABoCEBB4CGBBwAGhJwAGhIwAGgIQEHgIYEHAAaEnAAaEjAAaAhAQeAhgQcABoScABoSMABoCEBB4CGBBwAGhJwAGhIwAGgIQEHgIYEHAAaEnAAaEjAAaAhAQeAhq6acmiMcTzJvUnWkmwmub2qHrngzLuT/HqS787+eVdVPTDfcQGAZPod+F1JTlfV8SSnk9y9y5lPJ7m1qn46yTuSfGSM8bL5jAkA7LRnwMcY1yQ5keTM7NKZJCfGGOs7z1XVA1X17dmXn0uyku07dgBgzqbcgd+Q5ImqOpsks1+fnF3/fm5P8uWq+vqljwgAXGjSc+D7McZ4fZL3Jbltv9+7tnZ03uNwgfX1Y4c9whXBnhfPjhfPjl/cpgT88STXjzGOVNXZMcaRJNfNrj/PGOM1ST6c5JerqvY7zObmszl3bmu/38ZE6+vHsrHxzGGPcdmz58Wz48Wz48VaXV255JvWPR9Cr6qnkjyU5OTs0skkD1bVxs5zY4xbk3wkyVur6rOXNBUAcFFTH0K/I8m9Y4z3JPlWtp/jzhjj/iTvqar/SPKhJC9LcvcY4/z3/WZVfX6+IwMAkwJeVV9K8updrr95x7/fOse5AICL8E5sANCQgANAQwIOAA0JOAA0JOAA0JCAA0BDAg4ADQk4ADQk4ADQkIADQEMCDgANCTgANCTgANCQgANAQwIOAA0JOAA0JOAA0JCAA0BDAg4ADQk4ADQk4ADQkIADQEMCDgANCTgANCTgANCQgANAQwIOAA0JOAA0JOAA0JCAA0BDAg4ADQk4ADQk4ADQkIADQEMCDgANCTgANCTgANCQgANAQwIOAA0JOAA0JOAA0JCAA0BDAg4ADQk4ADQk4ADQkIADQEMCDgANCTgANCTgANCQgANAQwIOAA1dNeXQGON4knuTrCXZTHJ7VT1ywZkjST6Y5E1JtpL8cVX9xXzHBQCS6XfgdyU5XVXHk5xOcvcuZ34jyY8n+Ykkr0ly5xjjxnkMCQA835534GOMa5KcSHLb7NKZJH82xlivqo0dR9+e5J6qOpdkY4xxX5K3JfmTCXMcSZLV1ZX9zM4B2PFy2PPi2fHi2fHi7NjtkYP+jCkPod+Q5ImqOpskVXV2jPHk7PrOgL8qydd2fP3Y7MwU1ybJK17x8onHOai1taOHPcIVwZ4Xz44Xz46X4tokXz7IN056DnwJPpPktUm+keTsIc8CAIt2JNvx/sxBf8CUgD+e5PoxxpHZ3feRJNfNru/0WJIf3jHMhXfkF/Nckk9NPAsAl4MD3Xmft+eL2KrqqSQPJTk5u3QyyYMXPP+dJP+Q5LfHGKtjjPUkb0nyj5cyHACwu6mvQr8jyakxxsNJTs2+zhjj/jHGLbMzf5PkK0keSfLvSd5bVV+Z87wAQJKVra2tw54BANgn78QGAA0JOAA0JOAA0JCAA0BDS30jFx+KsngTd/zuJL+e5Luzf95VVQ8se9bOpux5x9mR5MEkH6qq31/elL1N3fEY49eSvDvJSrb/zHhjVf3PMmftauKfF9ck+atsv7Pm1Uk+keR3q+q7Sx63pTHG+5P8apIbk9xUVV/Y5cyBurfsO3AfirJ4U3b86SS3VtVPJ3lHko+MMV62xBkvB1P2fP4/zLuT3LfE2S4Xe+549n9jvTPJbVX1U0l+LsnTyxyyuSm/j9+V5L+r6uYkNyX5mSS/srwR27svyety8Tc2O1D3lhbwHR+KcmZ26UySE7M3fdnpex+KMnuzmPMfisIepu64qh6oqm/Pvvxctu9c1pY2aHP7+L2cJH+Q5J+TPLyk8S4L+9jx7yV5f1V9M0mq6umq+s7yJu1rHzveSnJsjLGa5KXZvgt/YmmDNldVn6qqC9+59EIH6t4y78Bf8KEoSc5/KMpOl/KhKFe6qTve6fYkX66qry9hvsvFpD2PMW5O8otJPrD0Cfub+nv5J5P86Bjjk2OMz44x/nCM4SNbiJxtAAABrUlEQVS0ppm64/clOZ7tz6r4ZpIHqurfljnoFeBA3fMitivYGOP12f6P8+ReZ9mfMcZLktyT5I7zf0CyEFcluTnbH3f8+iS/lOQ3D3Wiy8/bsv1I3bVJrk/yujHGWw93JJLlBvx7H4qSfO+5wYt9KMp5r9rlDLubuuOMMV6T5MNJ3lJVtdQp+5uy52uT/FiS+8cYX03yzmx/VsCfL3fUtqb+Xv5ako9W1XNV9UySjyX52aVO2tfUHZ9K8rezh3efzvaOf36pk17+DtS9pQXch6Is3tQdjzFuTfKRJG+tqs8ud8r+puy5qh6rqh+qqhur6sYkf5rt57h+Z+kDN7SPPy/+LskvjDFWZo96vCHJfy5v0r72seNHs/3q6Iwxrk7yxiQveCU1l+RA3Vv2Q+g+FGXxpuz4Q0leluTuMcZDs39uOpxx25qyZy7NlB3/fZKnkvxXtmP0xSR/eQizdjVlx+9M8toxxuezveOHs/30EBOMMT44xvh6klcm+fgY44uz65fcPR9mAgANeREbADQk4ADQkIADQEMCDgANCTgANCTgANCQgANAQwIOAA39f2yCw6deAjdrAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x864 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax =plt.subplots(2,1, figsize = (8, 12))\n",
    "# fig = plt.figure(figsize = (10,13));\n",
    "\n",
    "# Initiate plot\n",
    "sns.countplot(x = 'age', hue = 'income', data = adult_data[adult_data.sex=='Female'], saturation=1, ax=ax[0])\n",
    "sns.countplot(x = 'age', hue = 'income', data = adult_data[adult_data.sex=='Male'], saturation=1, ax=ax[1])\n",
    "\n",
    "# Add titles\n",
    "ax[0].set_title('Female', loc='center', fontsize = 14)\n",
    "ax[1].set_title('Male', loc='center', fontsize = 14)\n",
    "\n",
    "# Add labels\n",
    "ax[0].set_xlabel(\"Age\")\n",
    "ax[1].set_xlabel(\"Age\")\n",
    "ax[0].set_ylabel(\"Proportion of Records\")\n",
    "ax[1].set_ylabel(\"Proportion of Records\")\n",
    "\n",
    "# Add x_axis ticks\n",
    "new_ticks = [i.get_text() for i in ax[0].get_xticklabels()]\n",
    "ax[0].set_xticks(range(0, len(new_ticks), 10))\n",
    "ax[0].set_xticklabels(new_ticks[::10])\n",
    "ax[1].set_xticks(range(0, len(new_ticks), 10))\n",
    "ax[1].set_xticklabels(new_ticks[::10])\n",
    "\n",
    "# Optimize y_axis ticks\n",
    "total_F = adult_data[adult_data.sex=='Female'].shape[0]*1.\n",
    "total_M = adult_data[adult_data.sex=='Male'].shape[0]*1.\n",
    "ax[0].set_yticklabels(map('{:.1f}%'.format, 100*ax[0].yaxis.get_majorticklocs()/total_F))\n",
    "ax[1].set_yticklabels(map('{:.1f}%'.format, 100*ax[1].yaxis.get_majorticklocs()/total_M))\n",
    "\n",
    "# Change legend location\n",
    "ax[0].legend(loc=1, title='Income')\n",
    "ax[1].legend(loc=1, title='Income')\n",
    "\n",
    "# Set suptitle\n",
    "fig.suptitle(\"Income by Age\", fontsize = 16, y = 1.03)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'adult_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-afc7ed5afb7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Use occupation percentage of '>50K' as order of the plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0morder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0madult_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moccupation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0madult_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mincome\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'>50K'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0madult_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Plotting the income by age\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'adult_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Use occupation percentage of '>50K' as order of the plot\n",
    "order = (adult_data.occupation[adult_data.income=='>50K'].value_counts()/adult_data.shape[0]).index\n",
    "\n",
    "# Plotting the income by age\n",
    "plt.figure(figsize=(8,6))\n",
    "ax = sns.countplot(x = 'occupation', hue = 'income', order = order, data = adult_data, saturation=1)\n",
    "ax.set_title('Income by Occupation', fontsize = 14)\n",
    "ax.set_xlabel(\"Occupation\")\n",
    "ax.set_ylabel(\"Proportion of Records\")\n",
    "\n",
    "# new_ticks = [i.get_text() for i in ax.get_xticklabels()]\n",
    "# plt.xticks(range(0, len(new_ticks), 10), new_ticks[::10])\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"right\")\n",
    "\n",
    "total = adult_data.shape[0]*1.\n",
    "ax.set_yticklabels(map('{:.1f}%'.format, 100*ax.yaxis.get_majorticklocs()/total))\n",
    "ax.legend(loc=1, title='Income')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'adult_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-81c585d1acb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Use occupation percentage of '>50K' as order of the plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0morder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0madult_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrace\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0madult_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mincome\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'>50K'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0madult_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Plotting the income by age\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'adult_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Use occupation percentage of '>50K' as order of the plot\n",
    "order = (adult_data.race[adult_data.income=='>50K'].value_counts()/adult_data.shape[0]).index\n",
    "\n",
    "# Plotting the income by age\n",
    "plt.figure(figsize=(8,6))\n",
    "ax = sns.countplot(x = 'race', hue = 'income', order = order, data = adult_data, saturation=1)\n",
    "ax.set_title('Income by Race', fontsize = 14)\n",
    "ax.set_xlabel(\"Race\")\n",
    "ax.set_ylabel(\"Proportion of Records\")\n",
    "\n",
    "# new_ticks = [i.get_text() for i in ax.get_xticklabels()]\n",
    "# plt.xticks(range(0, len(new_ticks), 10), new_ticks[::10])\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"right\")\n",
    "\n",
    "total = adult_data.shape[0]*1.\n",
    "ax.set_yticklabels(map('{:.1f}%'.format, 100*ax.yaxis.get_majorticklocs()/total))\n",
    "ax.legend(loc=1, title='Income')\n",
    "\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    ax.text(p.get_x()+p.get_width()/2.,\n",
    "            height + 3,\n",
    "            '{:1.2f}%'.format(height/total*100.0),\n",
    "            ha=\"center\") \n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'adult_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-630fd1a068cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Use occupation percentage of '>50K' as order of the plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0morder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0madult_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meducation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0madult_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mincome\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'>50K'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0madult_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Plotting the income by age\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'adult_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Use occupation percentage of '>50K' as order of the plot\n",
    "order = (adult_data.education[adult_data.income=='>50K'].value_counts()/adult_data.shape[0]).index\n",
    "\n",
    "# Plotting the income by age\n",
    "plt.figure(figsize=(8,6))\n",
    "ax = sns.countplot(x = 'education', hue = 'income', order = order, data = adult_data, saturation=1)\n",
    "ax.set_title('Income by Education', fontsize = 14)\n",
    "ax.set_xlabel(\"Education\")\n",
    "ax.set_ylabel(\"Proportion of Records\")\n",
    "\n",
    "# new_ticks = [i.get_text() for i in ax.get_xticklabels()]\n",
    "# plt.xticks(range(0, len(new_ticks), 10), new_ticks[::10])\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"right\")\n",
    "\n",
    "total = adult_data.shape[0]*1.\n",
    "ax.set_yticklabels(map('{:.1f}%'.format, 100*ax.yaxis.get_majorticklocs()/total))\n",
    "ax.legend(loc=1, title='Income')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'adult_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-64152a0fa676>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Total number of records\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mn_records\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madult_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Number of records where individual's income is more than $50,000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mn_greater_50k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madult_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mincome\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'>50K'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'adult_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Total number of records\n",
    "n_records = adult_data.shape[0]\n",
    "\n",
    "# Number of records where individual's income is more than $50,000\n",
    "n_greater_50k = np.sum(adult_data.income=='>50K')\n",
    "\n",
    "# Number of records where individual's incomre is less than $50,000\n",
    "n_at_most_50k = np.sum(adult_data.income=='<=50K')\n",
    "\n",
    "# Percentage of indiciduals whose income is more than $50,000\n",
    "greater_percentage = round(np.mean(adult_data.income=='>50K')*100.00, 2)\n",
    "\n",
    "# Print the results\n",
    "print(\"Total number of records: {}\".format(n_records))\n",
    "print(\"Individuals making more than $50,000: {}\".format(n_greater_50k))\n",
    "print(\"Individuals making at most $50,000: {}\".format(n_at_most_50k))\n",
    "print(\"Percentage of individuals making more than $50,000: {}%\".format(greater_percentage))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Data\n",
    "\n",
    "Before data can be used as input for machine learning algorithms, it often must be cleaned, formatted, and restructured. After processing the missing entries, there are some qualities about certain features that must be adjusted. This preprocessing can help tremendously with the outcome and predictive power of nearly all learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming Skewed Continuous Features\n",
    "Skewness may violate model assumptions or may impair the interpretation of feature importance. Therefore, here I will apply logarithmic transformation on the skewed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'adult_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-910400a75e71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Check the skewness of numerical variables in data set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnum_col\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madult_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0madult_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'object'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Create figure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'adult_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Check the skewness of numerical variables in data set\n",
    "num_col = adult_train.dtypes[adult_train.dtypes != 'object'].index\n",
    "\n",
    "# Create figure\n",
    "fig = plt.figure(figsize = (10,13));\n",
    "\n",
    "# Skewed feature plotting\n",
    "for i, feature in enumerate(adult_train[num_col]):\n",
    "    ax = fig.add_subplot(3, 2, i+1)\n",
    "    ax.hist(adult_train[feature], bins = 25, color = '#00A0A0')\n",
    "    ax.set_title(\"'%s' Feature Distribution\"%(feature), fontsize = 14)\n",
    "    ax.set_xlabel(\"Value\")\n",
    "    ax.set_ylabel(\"Number of Records\")\n",
    "    ax.set_ylim((0, 2000))\n",
    "    ax.set_yticks([0, 500, 1000, 1500, 2000])\n",
    "    ax.set_yticklabels([0, 500, 1000, 1500, \">2000\"])\n",
    "\n",
    "# Plot aesthetics\n",
    "fig.suptitle(\"Skewed Distributions of Continuous Census Data Features\", fontsize = 16, y = 1.03)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown in the graph, there seems skewness in 'capital-gain' and 'capital-loss' features. Use quantitative result to confirm if I need to transform skewness in these two variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'adult_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-95a642b853f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Calculate skew and sort\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mskew_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madult_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mskewness\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Skew'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mskew_feats\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mskewness\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'adult_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Calculate skew and sort\n",
    "skew_feats = adult_train[num_col].skew().sort_values(ascending=False)\n",
    "skewness = pd.DataFrame({'Skew': skew_feats})\n",
    "skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'adult_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-7a034843d38a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Split the data into features and target label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mincome_raw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madult_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'income'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mfeature_raw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madult_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'income'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mincome_raw_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madult_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'income'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'adult_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Split the data into features and target label\n",
    "income_raw = adult_train['income']\n",
    "feature_raw = adult_train.drop('income', axis=1)\n",
    "\n",
    "income_raw_test = adult_test['income']\n",
    "feature_raw_test = adult_test.drop('income', axis=1)\n",
    "\n",
    "# Log transform the skewed feature highly-skewed feature 'capital-gain' and 'capital-loss'. \n",
    "skewed = ['capital-gain', 'capital-loss']\n",
    "features_log_transformed = pd.DataFrame(data=feature_raw)\n",
    "features_log_transformed[skewed] = feature_raw[skewed].apply(lambda x: np.log(x + 1))\n",
    "\n",
    "features_log_transformed_test = pd.DataFrame(data=feature_raw_test)\n",
    "features_log_transformed_test[skewed] = feature_raw_test[skewed].apply(lambda x: np.log(x + 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing Numerical Features\n",
    "In addition to performing transformations on features that are highly skewed, here will perform some type of scaling on numerical features. Applying a scaling to the data does not change the shape of each feature's distribution (such as 'capital-gain' or 'capital-loss' above); however, it is useful to scale the input attributes for a model that relies on the magnitude of values, such as distance measures used in k-nearest neighbors and in the preparation of coefficients in regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'features_log_transformed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-2c451e8e20d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# default=(0, 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfeatures_log_minmax_transform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures_log_transformed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mfeatures_log_minmax_transform\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum_col\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_log_transformed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'features_log_transformed' is not defined"
     ]
    }
   ],
   "source": [
    "# Initialize a scaler, then apply it to the features\n",
    "scaler = MinMaxScaler() # default=(0, 1)\n",
    "\n",
    "features_log_minmax_transform = pd.DataFrame(data = features_log_transformed)\n",
    "features_log_minmax_transform[num_col] = scaler.fit_transform(features_log_transformed[num_col])\n",
    "\n",
    "# Transform the test data set\n",
    "features_log_minmax_transform_test = pd.DataFrame(data = features_log_transformed_test)\n",
    "features_log_minmax_transform_test[num_col] = scaler.transform(features_log_transformed_test[num_col])\n",
    "\n",
    "# Show an example of a record with scaling applied\n",
    "display(features_log_minmax_transform.head())\n",
    "display(features_log_minmax_transform_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "\n",
    "There are several features for each record that are non-numeric. Typically, learning algorithms expect input to be numeric, which requires that non-numeric features (called *categorical variables*) be converted. Here convert categorical variables by using the **one-hot encoding** scheme.\n",
    "\n",
    "Additionally, as with the non-numeric features, I need to convert the non-numeric target label, `'income'` to numerical values for the learning algorithm to work. Since there are only two possible categories for this label (\"<=50K\" and \">50K\"), we can simply encode these two categories as `0` and `1`, respectively. The code cell below implement the following:\n",
    " - Use `sklearn.OneHotEncoder` to perform one-hot encoding on the `'features_log_minmax_transform'` data.  \n",
    "     - Note: Since the test data is separate, in case there are unseen categories in test data which will fail the model, here use sklearn.OneHotEncoder rather the pd.get_dummies()\n",
    " - Convert the target label `'income_raw'` to numerical entries.\n",
    "   - Set records with \"<=50K\" to `0` and records with \">50K\" to `1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'features_log_minmax_transform' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-711318d2b8c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Categorical columns' names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcat_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures_log_minmax_transform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures_log_minmax_transform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'object'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mcat_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfeatures_log_minmax_transform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcat_feats\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'features_log_minmax_transform' is not defined"
     ]
    }
   ],
   "source": [
    "# One-hot encode the 'features_log_minmax_transform' data using sklearn.OneHotEncoder\n",
    "\n",
    "# Categorical columns' names\n",
    "cat_feats = features_log_minmax_transform.dtypes[features_log_minmax_transform.dtypes=='object'].index.tolist()\n",
    "cat_idx = [features_log_minmax_transform.columns.get_loc(col) for col in cat_feats]\n",
    "\n",
    "# Create the encoder.\n",
    "encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "\n",
    "# Fit and transform the encoder on categorical features\n",
    "encoded_cat_feats = encoder.fit_transform(features_log_minmax_transform.loc[:,cat_feats])\n",
    "\n",
    "# Extract one-hot-encoder's feature names\n",
    "cat_col_name = features_log_minmax_transform.columns.get_values()[cat_idx].tolist()\n",
    "encoded_cat_feats_name = encoder.get_feature_names(cat_col_name)\n",
    "\n",
    "# Generate OHE dataframe and concatenate it with the numerical dataframe later\n",
    "encoded_cat_feats_df = pd.DataFrame(encoded_cat_feats, columns=encoded_cat_feats_name)\n",
    "encoded_cat_feats_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'encoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-33f9c4ea9b2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Apply OHE above to transform the test dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mencoded_cat_feats_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_log_minmax_transform_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcat_feats\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Generate OHE dataframe and concatenate it with the numerical dataframe later\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mencoded_cat_feats_df_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_cat_feats_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoded_cat_feats_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'encoder' is not defined"
     ]
    }
   ],
   "source": [
    "# Apply OHE above to transform the test dataset\n",
    "encoded_cat_feats_test = encoder.transform(features_log_minmax_transform_test.loc[:,cat_feats])\n",
    "\n",
    "# Generate OHE dataframe and concatenate it with the numerical dataframe later\n",
    "encoded_cat_feats_df_test = pd.DataFrame(encoded_cat_feats_test, columns=encoded_cat_feats_name)\n",
    "encoded_cat_feats_df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'features_log_minmax_transform' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-a2eba2d725fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Extract the dataframe with only numerical features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnum_feats_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures_log_minmax_transform\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Concatenate numerical and encoded categorical features together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_feats_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoded_cat_feats_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'features_log_minmax_transform' is not defined"
     ]
    }
   ],
   "source": [
    "# Extract the dataframe with only numerical features\n",
    "num_feats_df = features_log_minmax_transform[num_col].reset_index()\n",
    "\n",
    "# Concatenate numerical and encoded categorical features together\n",
    "X_train = pd.merge(num_feats_df, encoded_cat_feats_df, left_index=True, right_index=True).drop('index', axis=1)\n",
    "\n",
    "# Encode the 'income_raw' to numerical values\n",
    "y_train = income_raw.apply(lambda x: 1 if x == '>50K' else 0)\n",
    "\n",
    "print(\"{} total features after one-hot encoding.\".format(len(X_train.columns)))\n",
    "\n",
    "# Display several rows of processed dataframe\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'features_log_minmax_transform_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-7d501cd2440d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Do the same transformation on test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Extract the dataframe with only numerical features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnum_feats_df_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures_log_minmax_transform_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Concatenate numerical and encoded categorical features together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'features_log_minmax_transform_test' is not defined"
     ]
    }
   ],
   "source": [
    "# Do the same transformation on test data\n",
    "# Extract the dataframe with only numerical features\n",
    "num_feats_df_test = features_log_minmax_transform_test[num_col].reset_index()\n",
    "\n",
    "# Concatenate numerical and encoded categorical features together\n",
    "X_test = pd.merge(num_feats_df_test, encoded_cat_feats_df_test, left_index=True, right_index=True)\\\n",
    "            .drop('index', axis=1)\n",
    "\n",
    "# Encode the 'income_raw' to numerical values\n",
    "y_test = income_raw_test.apply(lambda x: 1 if x == '>50K' else 0)\n",
    "\n",
    "print(\"{} total features after one-hot encoding.\".format(len(X_test.columns)))\n",
    "\n",
    "# Display several rows of processed dataframe\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Model Performance\n",
    "\n",
    "In this section, I will investigate five different algorithms, and determine which is best at modeling the data. Four of these algorithms will be supervised learners, and the fifth algorithm is known as a *naive predictor*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Predictor\n",
    "\n",
    "Generate a naive predictor to show what a base model without any intelligence would look like. That is if we chose a model that always predicted an individual made more than $50,000, what would  that model's accuracy and F-score be on this dataset? Here assum that we consider more about to correctly predict individual who has incomre over 50K. \n",
    "\n",
    "\n",
    "Therefore, a model's ability to precisely predict those that make more than \\$50,000 is *more important* than the model's ability to **recall** those individuals. We can use **F-beta score** as a metric that considers both precision and recall:\n",
    "\n",
    "$$ F_{\\beta} = (1 + \\beta^2) \\cdot \\frac{precision \\cdot recall}{\\left( \\beta^2 \\cdot precision \\right) + recall} $$\n",
    "\n",
    "In particular, when $\\beta = 0.5$, more emphasis is placed on precision, which is also called the **F$_{0.5}$ score** (or F-score for simplicity).\n",
    "\n",
    "__Note__:\n",
    "* When we have a model that always predicts '1' (i.e. the individual makes more than 50k) then our model will have no True Negatives(TN) or False Negatives(FN) as we are not making any negative('0' value) predictions. Therefore our Accuracy in this case becomes the same as our Precision(True Positives/(True Positives + False Positives)) as every prediction that we have made with value '1' that should have '0' becomes a False Positive; therefore our denominator in this case is the total number of records we have in total. \n",
    "* Our Recall score(True Positives/(True Positives + False Negatives)) in this setting becomes 1 as we have no False Negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-6713dee30d21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Calculate accuracy, precision and recall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mrecall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_train' is not defined"
     ]
    }
   ],
   "source": [
    "'''\n",
    "TP = np.sum(income) # Counting the ones as this is the naive case. Note that 'income' is the 'income_raw' data \n",
    "encoded to numerical values done in the data preprocessing step.\n",
    "FP = income.count() - TP # Specific to the naive case\n",
    "\n",
    "TN = 0 # No predicted negatives in the naive case\n",
    "FN = 0 # No predicted negatives in the naive case\n",
    "'''\n",
    "\n",
    "# Calculate accuracy, precision and recall\n",
    "accuracy = np.sum(y_train)/ y_train.count()\n",
    "recall = np.sum(y_train) / np.sum(y_train)\n",
    "precision = np.sum(y_train) / y_train.count()\n",
    "\n",
    "# Calculate F-score using beta = 0.5 and correct values for precision and recall.\n",
    "fscore = (1 + 0.5*0.5)* precision* recall/ (0.5*0.5*precision + recall)\n",
    "\n",
    "# Print the results \n",
    "print(\"Naive Predictor: [Accuracy score: {:.4f}, F-score: {:.4f}]\".format(accuracy, fscore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised Lerning Models\n",
    "\n",
    "Apart from bench mark model, I'll chose four other models Logistic Regression, Random Forest, Ensemble Methods (AdaBoost) and Support Vector Machines (SVM) as a candidate to build the predictive model.\n",
    "\n",
    "- Logistic Regression  \n",
    "\n",
    "    - Logistic regression doesn't need too many computational resources. 's highly interpretable, and doesn't require input features to be scaled. It doesn't require any tuning, and is wasy to regularize.\n",
    "    - However, it can't solve non-linear problem with logistic regression since its secision surface is linear. It won't perform well with independent variables that are not correlated to the target variable or the variables correlated to each others\n",
    "    - In this case, the model is simply doing binary classification and most of features are correlated to the target variable.\n",
    "\n",
    "- Random Forest  \n",
    "\n",
    "    - RF can be used in data sets with large number of features and instances. It trains fast due to parallel tree generation. It has low variance compared to single decision tree due to uncorrelated trees.  \n",
    "    - Prediction time can be higher for complex models with large number of trees. Possible issues with diagonal decision boundaries  \n",
    "    - In this case, Given large number of training data and one hot encoded categorical features will be a good fit for the given problem.\n",
    "\n",
    "- Ensemble Methods -- AdaBoost  \n",
    "\n",
    "    - AdaBoost is easy to implement. It iteratively corrects the mistakes of the weak classifier and improves accuracy by combining weak learners. AdaBoost is not prone to overfitting.  \n",
    "    - AdaBoost is sensitive to noise data. It is highly affected by outliers because it tries to fit each point perfectly. AdaBoost is slower compared to XGBoost. Reference.  \n",
    "    - In this case, the final goal is to predict if the individual will have salary above 50K or not. AdaBoost, as one of the boosting algorithm, it focuses on classification problems and aims to convert a set of weak classifiers into a strong one. Reference\n",
    "\n",
    "\n",
    "\n",
    "- Support Vector Machines (SVM)  \n",
    "\n",
    "    - SVM has a regularisation parameter, which makes the user avoid over-fitting SVM usese the kernel trick, can build in expert knowledge about the problem via engineering the kernel It's defined by a convex optimisation problem for which there are efficient methods Reference  \n",
    "    - SVM only really covers the determination of the parameters for a given value of the regularisation and kernel parameters and choice of kernel. Therefore, the biggest disadvantages are choosing appropriately hyper parameters of the SVM that will allow for sufficient generalization performance Reference  \n",
    "    - In this case, the data is not highly skewed/ imbalanced which would be good to use SVM model. The number of features in this case is not too many so that SVM can still work well. And the problem is binary classification which is suitable for SVM. Reference\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Training and Predicting Pipeline\n",
    "To properly evaluate the performance of each model chosen above more efficiently, it's helpful to create a training and predicting pipeline that can quickly and effectively train models using various sizes of training data and perform predictions on the testing data.\n",
    "\n",
    "The code block below will implement the following:\n",
    " - Fit the learner to the sampled training data and record the training time.\n",
    " - Perform predictions on the test data `X_test`, and also on the first 300 training points `X_train[:300]`.\n",
    "   - Record the total prediction time.\n",
    " - Calculate the accuracy score for both the training subset and testing set.\n",
    " - Calculate the F-score for both the training subset and testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_predict(learner, sample_size, X_train, y_train, X_test, y_test): \n",
    "    '''\n",
    "    inputs:\n",
    "       - learner: the learning algorithm to be trained and predicted on\n",
    "       - sample_size: the size of samples (number) to be drawn from training set\n",
    "       - X_train: features training set\n",
    "       - y_train: income training set\n",
    "       - X_test: features testing set\n",
    "       - y_test: income testing set\n",
    "    '''\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Fit the learner to the training data using slicing with 'sample_size' \n",
    "    start = time() # Get start time\n",
    "    learner =  learner.fit(X_train[:sample_size], y_train[:sample_size])\n",
    "    end = time() # Get end time\n",
    "    \n",
    "    # Calculate the training time\n",
    "    results['train_time'] = end - start\n",
    "        \n",
    "    # Get the predictions on the test set(X_test),\n",
    "    # then get predictions on the first 300 training samples(X_train) using .predict()\n",
    "    start = time() # Get start time\n",
    "    predictions_test = learner.predict(X_test)\n",
    "    predictions_train = learner.predict(X_train[:300])\n",
    "    end = time() # Get end time\n",
    "    \n",
    "    # Calculate the total prediction time\n",
    "    results['pred_time'] = end - start\n",
    "            \n",
    "    # Compute accuracy on the first 300 training samples which is y_train[:300]\n",
    "    results['acc_train'] = accuracy_score(y_train[:300], predictions_train)\n",
    "        \n",
    "    # Compute accuracy on test set using accuracy_score()\n",
    "    results['acc_test'] = accuracy_score(y_test, predictions_test)\n",
    "    \n",
    "    # Compute F-score on the the first 300 training samples using fbeta_score()\n",
    "    results['f_train'] = fbeta_score(y_train[:300], predictions_train, average = 'binary', beta = 0.5)\n",
    "        \n",
    "    # Compute F-score on the test set which is y_test\n",
    "    results['f_test'] = fbeta_score(y_test, predictions_test, average = 'binary', beta = 0.5)\n",
    "       \n",
    "    # Success\n",
    "    print(\"{} trained on {} samples.\".format(learner.__class__.__name__, sample_size))\n",
    "        \n",
    "    # Return the results\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Model Evaluation\n",
    "\n",
    "In the next section:\n",
    "- Initialize the four models and store them in `'clf_A'`, `'clf_B'`, `'clf_C'` and `'clf_D'`.\n",
    "  - **Note:** Here use the default settings for each model — will tune one specific model in a later section.\n",
    "- Calculate the number of records equal to 1%, 10%, and 100% of the training data.\n",
    "  - Store those values in `'samples_1'`, `'samples_10'`, and `'samples_100'` respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-66c52ccc47c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Calculate the number of samples for 1%, 10%, and 100% of the training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0msamples_100\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0msamples_10\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0msamples_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Initialize the three models\n",
    "clf_A = LogisticRegression(random_state = 42)\n",
    "clf_B = RandomForestClassifier(random_state=42)\n",
    "clf_C = AdaBoostClassifier(random_state = 42)\n",
    "clf_D = SVC(random_state = 42)\n",
    "\n",
    "\n",
    "# Calculate the number of samples for 1%, 10%, and 100% of the training data\n",
    "samples_100 = int(len(X_train))\n",
    "samples_10 = int(len(X_train) / 10)\n",
    "samples_1 = int(len(X_train) / 100)\n",
    "\n",
    "# Collect results on the learners\n",
    "results = {}\n",
    "for clf in [clf_A, clf_B, clf_C, clf_D]:\n",
    "    clf_name = clf.__class__.__name__\n",
    "    results[clf_name] = {}\n",
    "    for i, samples in enumerate([samples_1, samples_10, samples_100]):\n",
    "        results[clf_name][i] = \\\n",
    "        train_predict(clf, samples, X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-fe2d4e91c001>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Quick view on three model's performance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'1%'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'10%'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'100%'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "# Quick view on three model's performance\n",
    "for i in results.items():\n",
    "    print (i[0])\n",
    "    display(pd.DataFrame(i[1]).rename(columns={0:'1%', 1:'10%', 2:'100%'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-adda8e9ed891>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Super loop to plot four panels of data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearner\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_time'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'pred_time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'acc_train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'acc_test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'f_train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'f_test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAs8AAAP6CAYAAABvsrAdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzs3X+I5nd97/3XzsaImL25ZTqBJI1uT3U/UJoU1qQSqIpoWo//3NKa2kUaOIIl/6xY6B9FjiUoB4Rb6CHcK0ljKTnabkUrEUp6AqV/tBakHkzqj9Z3gokmJrEZBglJSwV35/wx195n3G4y75m5rmt29vt4QNjMN99d3h/2ypvnXvudmSObm5sBAAB2tnLQAwAAwGEhngEAoEk8AwBAk3gGAIAm8QwAAE3iGQAAmsQzAAA0iWcAAGi6aqcbxhifSvIbSY4nuamqvnWJe44muSfJu5NsJvlkVX1mvqMC0GFvAyxO553nB5O8Lcn3X+GeDyR5Y5I3Jbktyd1jjOP7ng6AvbC3ARZkx3iuqq9U1dM73Pb+JPdX1fmqWs/W4r5jHgMCsDv2NsDi7PjYRtPr89PvcDyV5MZd/PxXJ7k1yXNJzs1pJoBlOJrkuiRfS/LjA55lN/azt+1s4DDb196eVzzv161J/u6ghwDYh7cm+cpBD7EkdjZwJdjT3p5XPD+V5A3ZKvjkP76jsZPnkuRHP/rXnD+/OaeRLn+rq9dkY+Olgx5jqZx5GqZ05pWVI3nd616bzPbYIbKfvW1nT4QzT8PUzrzfvT2veP5Ckg+NMb6UZDXJe7P1ySpd55Lk/PnNSS3iJJM7b+LMUzHBMx+2xxf2s7ft7Alx5mmY4pmzx7294ycMjjHuGWP8IMnPJvnrMca3Z9cfGmPcMrvts0meSPJ4kq8m+XhVPbGXgQDYH3sbYHGObG5eFn/SOJ7kyY2Nlyb1J5+1tWNZX3/xoMdYKmeehimdeWXlSFZXr0mSn0vyvYOdZmmOx86eBGeehqmdeb9723cYBACAJvEMAABN4hkAAJrEMwAANIlnAABoEs8AANAkngEAoEk8AwBAk3gGAIAm8QwAAE3iGQAAmsQzAAA0iWcAAGgSzwAA0CSeAQCgSTwDAECTeAYAgCbxDAAATeIZAACaxDMAADSJZwAAaBLPAADQJJ4BAKBJPAMAQJN4BgCAJvEMAABN4hkAAJrEMwAANIlnAABoEs8AANAkngEAoEk8AwBAk3gGAIAm8QwAAE3iGQAAmsQzAAA0iWcAAGgSzwAA0CSeAQCgSTwDAECTeAYAgCbxDAAATeIZAACaxDMAADSJZwAAaBLPAADQJJ4BAKBJPAMAQJN4BgCApqs6N40xTiR5IMlqko0kd1bV4xfdc22SP0lyY5Krk/xNkg9X1U/mOjEAr8jOBlic7jvP9yY5U1UnkpxJct8l7vlokn+uqpuT3JTkzUl+fS5TArAbdjbAguwYz7N3J04mOTu7dDbJyTHG2kW3biY5NsZYSfLqbL2T8cwcZwVgB3Y2wGJ1Htu4MckzVXUuSarq3Bjj2dn19W33fSLJXyR5Lslrk/x/VfX3uxlmdfWa3dx+RVhbO3bQIyydM0/DFM98mbCzF2iKr2tnnoYpnnmvWs88N92R5BtJ3pnkWJK/GmO8r6q+2P0FNjZeyvnzm3Mc6fK2tnYs6+svHvQYS+XM0zClM6+sHDmsEWln79KUXtcXOPM0TO3M+93bnWeen05ywxjjaJLMfrx+dn2700n+tKrOV9ULSb6c5B17ngyAvbCzARZox3iuqueTPJrk1OzSqSSPVNX6Rbc+meTdSTLGuDrJu5J8a36jArATOxtgsbpfbeOuJKfHGI9l692Ku5JkjPHQGOOW2T0fSfLWMcY3s7W4H0ty/5znBWBndjbAgrSeea6q7yR5yyWuv2fbv383ye3zGw2AvbCzARbHdxgEAIAm8QwAAE3iGQAAmsQzAAA0iWcAAGgSzwAA0CSeAQCgSTwDAECTeAYAgCbxDAAATeIZAACaxDMAADSJZwAAaBLPAADQJJ4BAKBJPAMAQJN4BgCAJvEMAABN4hkAAJrEMwAANIlnAABoEs8AANAkngEAoEk8AwBAk3gGAIAm8QwAAE3iGQAAmsQzAAA0iWcAAGgSzwAA0CSeAQCgSTwDAECTeAYAgCbxDAAATeIZAACaxDMAADSJZwAAaBLPAADQJJ4BAKBJPAMAQJN4BgCAJvEMAABN4hkAAJrEMwAANIlnAABoEs8AANAkngEAoEk8AwBA01Wdm8YYJ5I8kGQ1yUaSO6vq8Uvc95tJPpbkSJLNJO+qqn+Z37gA7MTOBlic7jvP9yY5U1UnkpxJct/FN4wxbklyd5Lbq+oXk/xKkhfmNCcAfXY2wILsGM9jjGuTnExydnbpbJKTY4y1i2793SSfqqofJklVvVBV/z7PYQF4ZXY2wGJ1Htu4MckzVXUuSarq3Bjj2dn19W33/UKSJ8cYf5vkmiRfSvLfqmpzzjMD8PLsbIAFaj3zvItf6+Yktye5Osn/TPJUkv/R/QVWV6+Z4ziHw9rasYMeYemceRqmeOZDxs7egym+rp15GqZ45r3qxPPTSW4YYxydvYNxNMn1s+vbfT/JF6vqx0l+PMb4cpJfzi4W8cbGSzl/fjpveqytHcv6+osHPcZSOfM0TOnMKytHLreItLMXZEqv6wuceRqmdub97u0dn3muqueTPJrk1OzSqSSPVNX6Rbf+WZJfHWMcGWO8Ksk7k/zjnicDYNfsbIDF6n61jbuSnB5jPJbk9OzjjDEemn3GdpL8eZLnk/xTthb3t5P88XzHBaDBzgZYkCObm5fFX7kdT/KkvwK88jnzNEzpzNv++u/nknzvYKdZmuOxsyfBmadhamfe7972HQYBAKBJPAMAQJN4BgCAJvEMAABN4hkAAJrEMwAANIlnAABoEs8AANAkngEAoEk8AwBAk3gGAIAm8QwAAE3iGQAAmsQzAAA0iWcAAGgSzwAA0CSeAQCgSTwDAECTeAYAgCbxDAAATeIZAACaxDMAADSJZwAAaBLPAADQJJ4BAKBJPAMAQJN4BgCAJvEMAABN4hkAAJrEMwAANIlnAABoEs8AANAkngEAoEk8AwBAk3gGAIAm8QwAAE3iGQAAmsQzAAA0iWcAAGgSzwAA0CSeAQCgSTwDAECTeAYAgCbxDAAATeIZAACaxDMAADSJZwAAaBLPAADQJJ4BAKDpqs5NY4wTSR5IsppkI8mdVfX4y9w7kjyS5NNV9XvzGhSAHjsbYHG67zzfm+RMVZ1IcibJfZe6aYxxdPbfHpzPeADsgZ0NsCA7xvMY49okJ5OcnV06m+TkGGPtErf/fpK/TPLY3CYEoM3OBliszmMbNyZ5pqrOJUlVnRtjPDu7vn7hpjHGzUl+Lck7knxsL8Osrl6zl592qK2tHTvoEZbOmadhime+TNjZCzTF17UzT8MUz7xXrWeedzLGeFWS+5P8l9mi3tOvs7HxUs6f35zHSIfC2tqxrK+/eNBjLJUzT8OUzryycuTQRaSdvTdTel1f4MzTMLUz73dvd555fjrJDbNn4y48I3f97PoF1yX5+SQPjTG+l+QjST40xvijPU8GwF7Y2QALtOM7z1X1/Bjj0SSnknxu9uMjVbW+7Z6nkvzMhY/HGHcnucZnbgMsl50NsFjdr7ZxV5LTY4zHkpyefZwxxkNjjFsWNRwAe2JnAyxI65nnqvpOkrdc4vp7Xub+u/c3FgB7ZWcDLI7vMAgAAE3iGQAAmsQzAAA0iWcAAGgSzwAA0CSeAQCgSTwDAECTeAYAgCbxDAAATeIZAACaxDMAADSJZwAAaBLPAADQJJ4BAKBJPAMAQJN4BgCAJvEMAABN4hkAAJrEMwAANIlnAABoEs8AANAkngEAoEk8AwBAk3gGAIAm8QwAAE3iGQAAmsQzAAA0iWcAAGgSzwAA0CSeAQCgSTwDAECTeAYAgCbxDAAATeIZAACaxDMAADSJZwAAaBLPAADQJJ4BAKBJPAMAQJN4BgCAJvEMAABN4hkAAJrEMwAANIlnAABoEs8AANAkngEAoEk8AwBAk3gGAICmqzo3jTFOJHkgyWqSjSR3VtXjF93zsSS/leQns38+WlUPz3dcAHZiZwMsTved53uTnKmqE0nOJLnvEvf8Q5Jbq+qXknwwyefHGK+Zz5gA7IKdDbAgO8bzGOPaJCeTnJ1dOpvk5Bhjbft9VfVwVf3b7MNvJDmSrXc9AFgSOxtgsTrvPN+Y5JmqOpcksx+fnV1/OXcm+W5V/WD/IwKwC3Y2wAK1nnnejTHG25N8Isntu/25q6vXzHucy97a2rGDHmHpnHkapnjmw8jO3p0pvq6deRqmeOa96sTz00luGGMcrapzY4yjSa6fXf8pY4zbknwuyf9TVbXbYTY2Xsr585u7/WmH1trasayvv3jQYyyVM0/DlM68snLkcotIO3tBpvS6vsCZp2FqZ97v3t7xsY2qej7Jo0lOzS6dSvJIVa1vv2+McWuSzyd5X1V9fc8TAbBndjbAYnUf27gryQNjjD9I8qNsPR+XMcZDSf6gqv5Xkk8neU2S+8YYF37eb1fVN+c7MgA7sLMBFqQVz1X1nSRvucT192z791vnOBcAe2RnAyyO7zAIAABN4hkAAJrEMwAANIlnAABoEs8AANAkngEAoEk8AwBAk3gGAIAm8QwAAE3iGQAAmsQzAAA0iWcAAGgSzwAA0CSeAQCgSTwDAECTeAYAgCbxDAAATeIZAACaxDMAADSJZwAAaBLPAADQJJ4BAKBJPAMAQJN4BgCAJvEMAABN4hkAAJrEMwAANIlnAABoEs8AANAkngEAoEk8AwBAk3gGAIAm8QwAAE3iGQAAmsQzAAA0iWcAAGgSzwAA0CSeAQCgSTwDAECTeAYAgCbxDAAATeIZAACaxDMAADSJZwAAaBLPAADQJJ4BAKBJPAMAQJN4BgCAJvEMAABNV3VuGmOcSPJAktUkG0nurKrHL7rnaJJ7krw7yWaST1bVZ+Y7LgA7sbMBFqf7zvO9Sc5U1YkkZ5Lcd4l7PpDkjUnelOS2JHePMY7PY0gAdsXOBliQHeN5jHFtkpNJzs4unU1ycoyxdtGt709yf1Wdr6r1JA8muWOewwLwyuxsgMXqPLZxY5JnqupcklTVuTHGs7Pr69vue32S72/7+KnZPR1Hk2Rl5Ujz9iuHM0+DM1+5tp3z6EHOsY2dvUDOPA3OfGXb795uPfO8BNclyete99qDnmPpVlevOegRls6Zp2GCZ74uyXcPeoglsbMnxJmnYYpnzh73dieen05ywxjj6OwdjKNJrp9d3+6pJG9I8rXZxxe/q/FKvpbkrUmeS3Ku+XMALgdHs7WAv7bTjUtiZwO8sn3t7R3juaqeH2M8muRUks/Nfnxk9ozcdl9I8qExxpey9Rne703ytuYcP07ylfbUAJeXy+YdZzsboGXPe7v71TbuSnJ6jPFYktOzjzPGeGiMccvsns8meSLJ40m+muTjVfXEXgcDYM/sbIAFObK5uXnQMwAAwKHgOwwCAECTeAYAgCbxDAAATeIZAACalvpNUsYYJ5I8kK0vi7SR5M6qevyie44muSfJu5NsJvlkVX1mmXPOU/PMH0vyW0l+Mvvno1X18LJnnZfOmbfdO5I8kuTTVfV7y5tyvrpnHmP8ZpKPJTmSrdf3u6rqX5Y567w0X9vXJvmTbH3nuquT/E2SD1fVT5Y87r6NMT6V5DeSHE9yU1V96xL3THF/TfHMdradfejY2fPb2ct+5/neJGeq6kSSM0nuu8Q9H0jyxiRvSnJbkrvHGMeXNuH8dc78D0lurapfSvLBJJ8fY7xmiTPOW+fMF1609yV5cImzLcqOZ559ibC7k9xeVb+Y5FeSvLDMIees8/v80ST/XFU3J7kpyZuT/PryRpyrB7P1dZBf6RuJTHF/TfHMdvbhZ2fb2cke99fS4nn2p5mTSc7OLp1NcnKMsXbRre9Pcn9VnZ99Uf8Hk9yxrDnnqXvmqnq4qv5t9uE3svUn3NWlDTpHu/h9TpLfT/KXSR5b0ngLsYsz/26ST1XVD5Okql6oqn9f3qTzs4szbyY5NsZYSfLqbL2T8czSBp2jqvpKVV38XfouNrn9lQme2c62sw8bO/tl7Wl/LfOd5xuTPFNV55Jk9uOzs+vbXfwtYp+6xD2HRffM292Z5LtV9YMlzLcIrTOPMW5O8mtJ/nDpE85f9/f5F5L8pzHG344xvj7G+K9jjCNLnnVeumf+RJIT2fo2zj9M8nBV/f0yB12yKe6vKZ55Ozv78LGz7ewL9rS/fMLgZWSM8fZsvXBPHfQsizTGeFWS+5PcdeF/5Im4KsnNSW5P8vYk/znJbx/oRIt3R7bembsuyQ1J3jbGeN/BjgTzYWdf8exsO/uSlhnPTye5YfbM1IVnp66fXd/uqSRv2Pbx6y9xz2HRPXPGGLcl+VyS91ZVLXXK+eqc+bokP5/koTHG95J8JMmHxhh/tNxR56b7+/z9JF+sqh9X1YtJvpzkl5c66fx0z3w6yZ/O/krshWyd+R1LnXS5pri/pnhmO9vOPmzs7Evb0/5aWjxX1fNJHs3/+RP6qSSPzJ4x2e4L2fqfcmX2LM57k/zFsuacp+6Zxxi3Jvl8kvdV1deXO+V8dc5cVU9V1c9U1fGqOp7kv2frmaPfWfrAc7CL1/afJfnVMcaR2Ts570zyj8ubdH52ceYns/VZzBljXJ3kXUn+w2c8X0Emt78ywTPb2Xb2YWNnv6w97a9lP7ZxV5LTY4zHsvWnm7uSZIzx0OyzWpPks0meSPJ4kq8m+XhVPbHkOeepc+ZPJ3lNkvvGGI/O/rnpYMadi86ZrzSdM/95kueT/FO2lti3k/zxAcw6L50zfyTJW8cY38zWmR/L1l//HjpjjHvGGD9I8rNJ/nqM8e3Z9anvryme2c4+/OxsOzvZ4/46srm5uaCxAQDgyuITBgEAoEk8AwBAk3gGAIAm8QwAAE3iGQAAmsQzAAA0iWcAAGgSzwAA0CSeAQCgSTwDAECTeAYAgCbxDAAATeIZAACaxDMAADSJZwAAaBLPAADQJJ4BAKBJPAMAQJN4BgCAJvEMAABN4hkAAJrEMwAANIlnAABoEs8AANAkngEAoEk8AwBAk3gGAIAm8QwAAE3iGQAAmsQzAAA0iWcAAGgSzwAA0CSeAQCgSTwDAECTeAYAgCbxDAAATVftdMMY41NJfiPJ8SQ3VdW3LnHP0ST3JHl3ks0kn6yqz8x3VAA67G2Axem88/xgkrcl+f4r3POBJG9M8qYktyW5e4xxfN/TAbAX9jbAguz4znNVfSVJxhivdNv7k9xfVeeTrI8xHkxyR5L/tznHq5PcmuS5JOeaPwfgcnA0yXVJvpbkxwc8S5Kl7G07GzjM9rW3d4znptfnp9/heCrJjbv4+bcm+bs5zQJwEN6a5CsHPcQu7Gdv29nAlWBPe3te8bxfzyXJj370rzl/fvOgZ1ma1dVrsrHx0kGPsVTOPA1TOvPKypG87nWvTWZ7bCLs7Ilw5mmY2pn3u7fnFc9PJXlDtt7+Tv7jOxo7OZck589vTmoRJ5nceRNnnooJnvmwPb6wn71tZ0+IM0/DFM+cPe7tecXzF5J8aIzxpSSrSd6brU9WAeDyZG8D7MGOX21jjHHPGOMHSX42yV+PMb49u/7QGOOW2W2fTfJEkseTfDXJx6vqiQXNDMArsLcBFufI5uZl8Tb98SRPbmy8NKm/NlhbO5b19RcPeoylcuZpmNKZV1aOZHX1miT5uSTfO9hpluZ47OxJcOZpmNqZ97u3fYdBAABoEs8AANAkngEAoEk8AwBAk3gGAIAm8QwAAE3iGQAAmsQzAAA0iWcAAGgSzwAA0CSeAQCgSTwDAECTeAYAgCbxDAAATeIZAACaxDMAADSJZwAAaBLPAADQJJ4BAKBJPAMAQJN4BgCAJvEMAABN4hkAAJrEMwAANIlnAABoEs8AANAkngEAoEk8AwBAk3gGAIAm8QwAAE3iGQAAmsQzAAA0iWcAAGgSzwAA0CSeAQCgSTwDAECTeAYAgCbxDAAATeIZAACaxDMAADSJZwAAaBLPAADQJJ4BAKBJPAMAQJN4BgCAJvEMAABN4hkAAJrEMwAANF3VuWmMcSLJA0lWk2wkubOqHr/onmuT/EmSG5NcneRvkny4qn4y14kBeEV2NsDidN95vjfJmao6keRMkvsucc9Hk/xzVd2c5KYkb07y63OZEoDdsLMBFmTHeJ69O3EyydnZpbNJTo4x1i66dTPJsTHGSpJXZ+udjGfmOCsAO7CzARar887zjUmeqapzSTL78dnZ9e0+keREkueS/DDJw1X193OcFYCd2dkAC9R65rnpjiTfSPLOJMeS/NUY431V9cXuL7C6es0cxzkc1taOHfQIS+fM0zDFMx8ydvYeTPF17czTMMUz71Unnp9OcsMY42hVnRtjHE1y/ez6dqeTfLCqzid5YYzx5STvSNJexBsbL+X8+c3u7Yfe2tqxrK+/eNBjLJUzT8OUzryycuRyi0g7e0Gm9Lq+wJmnYWpn3u/e3vGxjap6PsmjSU7NLp1K8khVrV9065NJ3p0kY4yrk7wrybf2PBkAu2ZnAyxW96tt3JXk9BjjsWy9W3FXkowxHhpj3DK75yNJ3jrG+Ga2FvdjSe6f87wA7MzOBliQ1jPPVfWdJG+5xPX3bPv37ya5fX6jAbAXdjbA4vgOgwAA0CSeAQCgSTwDAECTeAYAgCbxDAAATeIZAACaxDMAADSJZwAAaBLPAADQJJ4BAKBJPAMAQJN4BgCAJvEMAABN4hkAAJrEMwAANIlnAABoEs8AANAkngEAoEk8AwBAk3gGAIAm8QwAAE3iGQAAmsQzAAA0iWcAAGgSzwAA0CSeAQCgSTwDAECTeAYAgCbxDAAATeIZAACaxDMAADSJZwAAaBLPAADQJJ4BAKBJPAMAQJN4BgCAJvEMAABN4hkAAJrEMwAANIlnAABoEs8AANAkngEAoEk8AwBAk3gGAIAm8QwAAE3iGQAAmsQzAAA0iWcAAGgSzwAA0HRV56YxxokkDyRZTbKR5M6qevwS9/1mko8lOZJkM8m7qupf5jcuADuxswEWp/vO871JzlTViSRnktx38Q1jjFuS3J3k9qr6xSS/kuSFOc0JQJ+dDbAgO8bzGOPaJCeTnJ1dOpvk5Bhj7aJbfzfJp6rqh0lSVS9U1b/Pc1gAXpmdDbBYncc2bkzyTFWdS5KqOjfGeHZ2fX3bfb+Q5Mkxxt8muSbJl5L8t6ra7A6zunpNe/ArxdrasYMeYemceRqmeObLhJ29QFN8XTvzNEzxzHvVeuZ5F7/WzUluT3J1kv+Z5Kkk/6P7C2xsvJTz59t7+9BbWzuW9fUXD3qMpXLmaZjSmVdWjhzWiLSzd2lKr+sLnHkapnbm/e7tzjPPTye5YYxxNElmP14/u77d95N8sap+XFUvJvlykl/e82QA7IWdDbBAO8ZzVT2f5NEkp2aXTiV5pKrWL7r1z5L86hjjyBjjVUnemeQf5zksAK/MzgZYrO5X27gryekxxmNJTs8+zhjjodlnbCfJnyd5Psk/ZWtxfzvJH893XAAa7GyABTmyuXlZPK92PMmTnp+78jnzNEzpzNuenfu5JN872GmW5njs7Elw5mmY2pn3u7d9h0EAAGgSzwAA0CSeAQCgSTwDAECTeAYAgCbxDAAATeIZAACaxDMAADSJZwAAaBLPAADQJJ4BAKBJPAMAQJN4BgCAJvEMAABN4hkAAJrEMwAANIlnAABoEs8AANAkngEAoEk8AwBAk3gGAIAm8QwAAE3iGQAAmsQzAAA0iWcAAGgSzwAA0CSeAQCgSTwDAECTeAYAgCbxDAAATeIZAACaxDMAADSJZwAAaBLPAADQJJ4BAKBJPAMAQJN4BgCAJvEMAABN4hkAAJrEMwAANIlnAABoEs8AANAkngEAoEk8AwBAk3gGAIAm8QwAAE3iGQAAmsQzAAA0XdW5aYxxIskDSVaTbCS5s6oef5l7R5JHkny6qn5vXoMC0GNnAyxO953ne5OcqaoTSc4kue9SN40xjs7+24PzGQ+APbCzARZkx3geY1yb5GSSs7NLZ5OcHGOsXeL230/yl0kem9uEALTZ2QCL1Xnn+cYkz1TVuSSZ/fjs7Pr/b4xxc5JfS/KH8x4SgDY7G2CBWs8872SM8aok9yf5L1V1busRut1bXb1mHuMcKmtrxw56hKVz5mmY4pkPCzt776b4unbmaZjimfeqE89PJ7lhjHF0tmSPJrl+dv2C65L8fJKHZkv4/05yZIzxf1XV73SH2dh4KefPb/anP+TW1o5lff3Fgx5jqZx5GqZ05pWVI5dbRNrZCzKl1/UFzjwNUzvzfvf2jvFcVc+PMR5NcirJ52Y/PlJV69vueSrJz1z4eIxxd5JrfOY2wHLZ2QCL1f1qG3clOT3GeCzJ6dnHGWM8NMa4ZVHDAbAndjbAgrSeea6q7yR5yyWuv+dl7r97f2MBsFd2NsDi+A6DAADQJJ4BAKBJPAMAQJN4BgCAJvEMAABN4hkAAJrEMwAANIlnAABoEs8AANAkngEAoEk8AwBAk3gGAIAm8QwAAE3iGQAAmsQzAAA0iWcAAGgSzwAA0CSeAQCgSTwDAECTeAYAgCbxDAAATeIZAACaxDMAADSJZwAAaBLPAADQJJ4BAKBJPAMAQJN4BgCAJvEMAABN4hkAAJrEMwAANIlnAABoEs8AANAkngEAoEk8AwBAk3gGAIAm8QwAAE3iGQAAmsQzAAA0iWcAAGgSzwAA0CSeAQCgSTwDAECTeAYAgCbxDAAATeIZAACaxDMAADSJZwAAaBLPAADQdFXnpjHGiSQPJFlNspHkzqp6/KJ7Ppbkt5L8ZPbPR6vq4fmOC8BO7GyAxem+83xvkjNVdSLJmST3XeKef0hya1X9UpIPJvn8GOM18xkTgF2wswEWZMd4HmNcm+RkkrOzS2eTnBxjrG2/r6oerqp/m334jSRHsvWuBwBLYmcDLFbnsY0bkzxTVeeSpKrOjTGenV1ff5mfc2eS71bVD3YzzOrqNbu5/YqwtnbsoEdYOmeehikwte7fAAAcQ0lEQVSe+TJhZy/QFF/XzjwNUzzzXrWeed6NMcbbk3wiye27/bkbGy/l/PnNeY902VpbO5b19RcPeoylcuZpmNKZV1aOHOqItLP7pvS6vsCZp2FqZ97v3u488/x0khvGGEeTZPbj9bPrP2WMcVuSzyV5b1XVnqcCYK/sbIAF2jGeq+r5JI8mOTW7dCrJI1X1U3/9N8a4Ncnnk7yvqr4+70EB2JmdDbBY3cc27krywBjjD5L8KFvPx2WM8VCSP6iq/5Xk00lek+S+McaFn/fbVfXN+Y4MwA7sbIAFacVzVX0nyVsucf092/791jnOBcAe2dkAi+M7DAIAQJN4BgCAJvEMAABN4hkAAJrEMwAANIlnAABoEs8AANAkngEAoEk8AwBAk3gGAIAm8QwAAE3iGQAAmsQzAAA0iWcAAGgSzwAA0CSeAQCgSTwDAECTeAYAgCbxDAAATeIZAACaxDMAADSJZwAAaBLPAADQJJ4BAKBJPAMAQJN4BgCAJvEMAABN4hkAAJrEMwAANIlnAABoEs8AANAkngEAoEk8AwBAk3gGAIAm8QwAAE3iGQAAmsQzAAA0iWcAAGgSzwAA0CSeAQCgSTwDAECTeAYAgCbxDAAATeIZAACaxDMAADSJZwAAaBLPAADQJJ4BAKDpqs5NY4wTSR5IsppkI8mdVfX4RfccTXJPkncn2Uzyyar6zHzHBWAndjbA4nTfeb43yZmqOpHkTJL7LnHPB5K8McmbktyW5O4xxvF5DAnArtjZAAuyYzyPMa5NcjLJ2dmls0lOjjHWLrr1/Unur6rzVbWe5MEkd8xzWABemZ0NsFidxzZuTPJMVZ1Lkqo6N8Z4dnZ9fdt9r0/y/W0fPzW7p+NokqysHGnefuVw5mlw5ivXtnMePcg5trGzF8iZp8GZr2z73dutZ56X4Loked3rXnvQcyzd6uo1Bz3C0jnzNEzwzNcl+e5BD7EkdvaEOPM0TPHM2ePe7sTz00luGGMcnb2DcTTJ9bPr2z2V5A1Jvjb7+OJ3NV7J15K8NclzSc41fw7A5eBothbw13a6cUnsbIBXtq+9vWM8V9XzY4xHk5xK8rnZj4/MnpHb7gtJPjTG+FK2PsP7vUne1pzjx0m+0p4a4PJy2bzjbGcDtOx5b3e/2sZdSU6PMR5Lcnr2ccYYD40xbpnd89kkTyR5PMlXk3y8qp7Y62AA7JmdDbAgRzY3Nw96BgAAOBR8h0EAAGgSzwAA0CSeAQCgSTwDAECTeAYAgKalfofBMcaJJA9k62uKbiS5s6oev+ieo0nuSfLuJJtJPllVn1nmnPPUPPPHkvxWkp/M/vloVT287FnnpXPmbfeOJI8k+XRV/d7yppyv7pnHGL+Z5GNJjmTr9f2uqvqXZc46L83X9rVJ/iRb3/b56iR/k+TDVfWTJY+7b2OMTyX5jSTHk9xUVd+6xD1T3F9TPLOdbWcfOnb2/Hb2st95vjfJmao6keRMkvsucc8HkrwxyZuS3Jbk7jHG8aVNOH+dM/9Dklur6peSfDDJ58cYr1nijPPWOfOFF+19SR5c4myLsuOZZ19f9+4kt1fVLyb5lSQvLHPIOev8Pn80yT9X1c1Jbkry5iS/vrwR5+rBbH0TkVf6LnxT3F9TPLOdffjZ2XZ2ssf9tbR4nv1p5mSSs7NLZ5OcHGOsXXTr+5PcX1XnZ98R68EkdyxrznnqnrmqHq6qf5t9+I1s/Ql3dWmDztEufp+T5PeT/GWSx5Y03kLs4sy/m+RTVfXDJKmqF6rq35c36fzs4sybSY6NMVaSvDpb72Q8s7RB56iqvlJVF3+L64tNbn9lgme2s+3sw8bOfll72l/LfOf5xiTPVNW5JJn9+Ozs+navz0//KeGpS9xzWHTPvN2dSb5bVT9YwnyL0DrzGOPmJL+W5A+XPuH8dX+ffyHJfxpj/O0Y4+tjjP86xjiy5FnnpXvmTyQ5keS5JD9M8nBV/f0yB12yKe6vKZ55Ozv78LGz7ewL9rS/fMLgZWSM8fZsvXBPHfQsizTGeFWS+5PcdeF/5Im4KsnNSW5P8vYk/znJbx/oRIt3R7bembsuyQ1J3jbGeN/BjgTzYWdf8exsO/uSlhnPTye5YfbM1IVnp66fXd/uqSRv2Pbx6y9xz2HRPXPGGLcl+VyS91ZVLXXK+eqc+bokP5/koTHG95J8JMmHxhh/tNxR56b7+/z9JF+sqh9X1YtJvpzkl5c66fx0z3w6yZ/O/krshWyd+R1LnXS5pri/pnhmO9vOPmzs7Evb0/5aWjxX1fNJHs3/+RP6qSSPzJ4x2e4L2fqfcmX2LM57k/zFsuacp+6Zxxi3Jvl8kvdV1deXO+V8dc5cVU9V1c9U1fGqOp7kv2frmaPfWfrAc7CL1/afJfnVMcaR2Ts570zyj8ubdH52ceYns/VZzBljXJ3kXUn+w2c8X0Emt78ywTPb2Xb2YWNnv6w97a9lP7ZxV5LTY4zHsvWnm7uSZIzx0OyzWpPks0meSPJ4kq8m+XhVPbHkOeepc+ZPJ3lNkvvGGI/O/rnpYMadi86ZrzSdM/95kueT/FO2lti3k/zxAcw6L50zfyTJW8cY38zWmR/L1l//HjpjjHvGGD9I8rNJ/nqM8e3Z9anvryme2c4+/OxsOzvZ4/46srm5uaCxAQDgyuITBgEAoEk8AwBAk3gGAIAm8QwAAE3iGQAAmsQzAAA0iWcAAGgSzwAA0CSeAQCgSTwDAECTeAYAgCbxDAAATeIZAACaxDMAADSJZwAAaBLPAADQJJ4BAKBJPAMAQJN4BgCAJvEMAABN4hkAAJrEMwAANIlnAABoEs8AANAkngEAoEk8AwBAk3gGAIAm8QwAAE3iGQAAmsQzAAA0iWcAAGgSzwAA0CSeAQCgSTwDAECTeAYAgKardrphjPGpJL+R5HiSm6rqW5e452iSe5K8O8lmkk9W1WfmOyoAHfY2wOJ03nl+MMnbknz/Fe75QJI3JnlTktuS3D3GOL7v6QDYC3sbYEF2jOeq+kpVPb3Dbe9Pcn9Vna+q9Wwt7jvmMSAAu2NvAyzOjo9tNL0+P/0Ox1NJbtzFz391kluTPJfk3JxmAliGo0muS/K1JD8+4Fl2Yz97284GDrN97e15xfN+3Zrk7w56CIB9eGuSrxz0EEtiZwNXgj3t7XnF81NJ3pCtgk/+4zsaO3kuSX70o3/N+fObcxrp8re6ek02Nl466DGWypmnYUpnXlk5kte97rXJbI8dIvvZ23b2RDjzNEztzPvd2/OK5y8k+dAY40tJVpO8N1ufrNJ1LknOn9+c1CJOMrnzJs48FRM882F7fGE/e9vOnhBnnoYpnjl73Ns7fsLgGOOeMcYPkvxskr8eY3x7dv2hMcYts9s+m+SJJI8n+WqSj1fVE3sZCID9sbcBFufI5uZl8SeN40me3Nh4aVJ/8llbO5b19RcPeoylcuZpmNKZV1aOZHX1miT5uSTfO9hpluZ47OxJcOZpmNqZ97u3fYdBAABoEs8AANAkngEAoEk8AwBAk3gGAIAm8QwAAE3iGQAAmsQzAAA0iWcAAGgSzwAA0CSeAQCgSTwDAECTeAYAgCbxDAAATeIZAACaxDMAADSJZwAAaBLPAADQJJ4BAKBJPAMAQJN4BgCAJvEMAABN4hkAAJrEMwAANIlnAABoEs8AANAkngEAoEk8AwBAk3gGAIAm8QwAAE3iGQAAmsQzAAA0iWcAAGgSzwAA0CSeAQCgSTwDAECTeAYAgCbxDAAATeIZAACaxDMAADSJZwAAaBLPAADQJJ4BAKBJPAMAQJN4BgCAJvEMAABN4hkAAJrEMwAANF3VuWmMcSLJA0lWk2wkubOqHr/onmuT/EmSG5NcneRvkny4qn4y14kBeEV2NsDidN95vjfJmao6keRMkvsucc9Hk/xzVd2c5KYkb07y63OZEoDdsLMBFmTHeJ69O3EyydnZpbNJTo4x1i66dTPJsTHGSpJXZ+udjGfmOCsAO7CzARar887zjUmeqapzSTL78dnZ9e0+keREkueS/DDJw1X193OcFYCd2dkAC9R65rnpjiTfSPLOJMeS/NUY431V9cXuL7C6es0cxzkc1taOHfQIS+fM0zDFMx8ydvYeTPF17czTMMUz71Unnp9OcsMY42hVnRtjHE1y/ez6dqeTfLCqzid5YYzx5STvSNJexBsbL+X8+c3u7Yfe2tqxrK+/eNBjLJUzT8OUzryycuRyi0g7e0Gm9Lq+wJmnYWpn3u/e3vGxjap6PsmjSU7NLp1K8khVrV9065NJ3p0kY4yrk7wrybf2PBkAu2ZnAyxW96tt3JXk9BjjsWy9W3FXkowxHhpj3DK75yNJ3jrG+Ga2FvdjSe6f87wA7MzOBliQ1jPPVfWdJG+5xPX3bPv37ya5fX6jAbAXdjbA4vgOgwAA0CSeAQCgSTwDAECTeAYAgCbxDAAATeIZAACaxDMAADSJZwAAaBLPAADQJJ4BAKBJPAMAQJN4BgCAJvEMAABN4hkAAJrEMwAANIlnAABoEs8AANAkngEAoEk8AwBAk3gGAIAm8QwAAE3iGQAAmsQzAAA0iWcAAGgSzwAA0CSeAQCgSTwDAECTeAYAgCbxDAAATeIZAACaxDMAADSJZwAAaBLPAADQJJ4BAKBJPAMAQJN4BgCAJvEMAABN4hkAAJrEMwAANIlnAABoEs8AANAkngEAoEk8AwBAk3gGAIAm8QwA/O/27i/E8rO8A/h3d6MlNLmQcQJJGt1W3QdEI2yNEvAPolHrTaX13yIGKlhys0XBC5FGglIQKrRIN2SNUlKta1BLBFkaKL0oFkSLG7Van12MmpioWZYSImLA3enFnKXT7cZ5Z/acMzv7+3xgmJw37wzPw/z24Tu/ec85wCDhGQAABgnPAAAwSHgGAIBBwjMAAAy6amRTVR1Icl+SlSRnktze3acusu8dSe5MsifJWpI3dPcv5lcuAJsxswEWZ/TO8z1JjnT3gSRHkhy9cENVvTzJXUlu6+6XJHlVkifnVCcA48xsgAXZNDxX1XVJDiY5Nls6luRgVa1esPUDST7R3T9Pku5+srt/Pc9iAfjtzGyAxRo5tnFTkse6+2ySdPfZqnp8tn56w74XJ/lRVf1bkmuS/FOSv+rutTnXDMAzM7MBFmjozPMWvtfNSW5L8uwk/5zkkST/MPoNVlaumWM5u8Pq6rU7XcLS6XkaptjzLmNmb8MUr2s9T8MUe96ukfD8aJIbq2rf7A7GviQ3zNY3+kmSL3X300merqqvJHlFtjCIz5z5Zc6dm85Nj9XVa3P69FM7XcZS6XkaptTz3r17LrcQaWYvyJSu6/P0PA1T6/lS5/amZ567+4kkDyU5NFs6lOREd5++YOvnk7yxqvZU1bOSvD7Jt7ddGQBbZmYDLNboq23ckeRwVZ1Mcnj2OFV1fPaM7ST5QpInknw/64P7e0k+M99yARhgZgMsyJ61tcviT277k/zInwCvfHqehin1vOHPf7+f5Mc7W83S7I+ZPQl6noap9Xypc9s7DAIAwCDhGQAABgnPAAAwSHgGAIBBwjMAAAwSngEAYJDwDAAAg4RnAAAYJDwDAMAg4RkAAAYJzwAAMEh4BgCAQcIzAAAMEp4BAGCQ8AwAAIOEZwAAGCQ8AwDAIOEZAAAGCc8AADBIeAYAgEHCMwAADBKeAQBgkPAMAACDhGcAABgkPAMAwCDhGQAABgnPAAAwSHgGAIBBwjMAAAwSngEAYJDwDAAAg4RnAAAYJDwDAMAg4RkAAAYJzwAAMEh4BgCAQcIzAAAMEp4BAGCQ8AwAAIOEZwAAGCQ8AwDAIOEZAAAGCc8AADBIeAYAgEHCMwAADBKeAQBgkPAMAACDhGcAABgkPAMAwKCrRjZV1YEk9yVZSXImye3dfeoZ9laSE0nu7u4PzqtQAMaY2QCLM3rn+Z4kR7r7QJIjSY5ebFNV7Zv9vwfmUx4A22BmAyzIpuG5qq5LcjDJsdnSsSQHq2r1Its/lOSrSU7OrUIAhpnZAIs1cmzjpiSPdffZJOnus1X1+Gz99PlNVXVzkjcleV2SO7dTzMrKNdv5sl1tdfXanS5h6fQ8DVPs+TJhZi/QFK9rPU/DFHverqEzz5upqmcluTfJn80G9ba+z5kzv8y5c2vzKGlXWF29NqdPP7XTZSyVnqdhSj3v3btn14VIM3t7pnRdn6fnaZhaz5c6t0fOPD+a5MbZ2bjzZ+RumK2fd32SFyQ5XlU/TvL+JO+rqk9tuzIAtsPMBligTe88d/cTVfVQkkNJPjf7fKK7T2/Y80iS555/XFV3JbnGM7cBlsvMBlis0VfbuCPJ4ao6meTw7HGq6nhVvXxRxQGwLWY2wIIMnXnu7h8keeVF1t/yDPvvurSyANguMxtgcbzDIAAADBKeAQBgkPAMAACDhGcAABgkPAMAwCDhGQAABgnPAAAwSHgGAIBBwjMAAAwSngEAYJDwDAAAg4RnAAAYJDwDAMAg4RkAAAYJzwAAMEh4BgCAQcIzAAAMEp4BAGCQ8AwAAIOEZwAAGCQ8AwDAIOEZAAAGCc8AADBIeAYAgEHCMwAADBKeAQBgkPAMAACDhGcAABgkPAMAwCDhGQAABgnPAAAwSHgGAIBBwjMAAAwSngEAYJDwDAAAg4RnAAAYJDwDAMAg4RkAAAYJzwAAMEh4BgCAQcIzAAAMEp4BAGCQ8AwAAIOEZwAAGCQ8AwDAIOEZAAAGCc8AADBIeAYAgEFXjWyqqgNJ7kuykuRMktu7+9QFe+5M8q4kv5l9fLi7H5xvuQBsxswGWJzRO8/3JDnS3QeSHEly9CJ7vpHklu5+WZL3Jrm/qq6eT5kAbIGZDbAgm4bnqrouycEkx2ZLx5IcrKrVjfu6+8Hu/tXs4XeS7Mn6XQ8AlsTMBliskTvPNyV5rLvPJsns8+Oz9Wdye5IfdvdPL71EALbAzAZYoKEzz1tRVa9N8rEkt231a1dWrpl3OZe91dVrd7qEpdPzNEyx593IzN6aKV7Xep6GKfa8XSPh+dEkN1bVvu4+W1X7ktwwW/8/qurWJJ9L8sfd3Vst5syZX+bcubWtftmutbp6bU6ffmqny1gqPU/DlHreu3fP5RYizewFmdJ1fZ6ep2FqPV/q3N702EZ3P5HkoSSHZkuHkpzo7tMb91XVLUnuT/K27v7WtisCYNvMbIDFGj22cUeS+6rqI0n+O+vn41JVx5N8pLv/I8ndSa5OcrSqzn/de7r7u/MtGYBNmNkACzIUnrv7B0leeZH1t2z471vmWBcA22RmAyyOdxgEAIBBwjMAAAwSngEAYJDwDAAAg4RnAAAYJDwDAMAg4RkAAAYJzwAAMEh4BgCAQcIzAAAMEp4BAGCQ8AwAAIOEZwAAGCQ8AwDAIOEZAAAGCc8AADBIeAYAgEHCMwAADBKeAQBgkPAMAACDhGcAABgkPAMAwCDhGQAABgnPAAAwSHgGAIBBwjMAAAwSngEAYJDwDAAAg4RnAAAYJDwDAMAg4RkAAAYJzwAAMEh4BgCAQcIzAAAMEp4BAGCQ8AwAAIOEZwAAGCQ8AwDAIOEZAAAGCc8AADBIeAYAgEHCMwAADBKeAQBgkPAMAACDhGcAABgkPAMAwCDhGQAABgnPAAAwSHgGAIBBV41sqqoDSe5LspLkTJLbu/vUBXv2JflkkjcnWUvy8e7+9HzLBWAzZjbA4ozeeb4nyZHuPpDkSJKjF9nz7iQvTPKiJLcmuauq9s+jSAC2xMwGWJBN7zxX1XVJDia5bbZ0LMnfVdVqd5/esPWdSe7t7nNJTlfVA0nenuSvB+rYlyR79+7ZSu1XBD1Pg56vXBv63LeTdZxnZi+WnqdBz1e2S53bI8c2bkryWHefTZLuPltVj8/WNw7i5yX5yYbHj8z2jLg+SZ7znN8d3H7lWFm5ZqdLWDo9T8MEe74+yQ93uoiY2Qs1wetazxMxxZ6zzbk9dOZ5Cb6Z5NVJfpbk7A7XArAV+7I+gL+504UskZkN7GaXNLdHwvOjSW6sqn2zOxj7ktwwW9/okSTP31DIhXc1fpunk3xtcC/A5eZyuON8npkNsLltz+1NnzDY3U8keSjJodnSoSQnLjg7lyRfTPK+qtpbVatJ3prky9stDICtM7MBFmv01TbuSHK4qk4mOTx7nKo6XlUvn+35bJKHk5xK8vUkH+3uh+dcLwCbM7MBFmTP2traTtcAAAC7gncYBACAQcIzAAAMEp4BAGCQ8AwAAIOW+iYpVXUgyX1JVpKcSXJ7d5+6YM++JJ9M8uYka0k+3t2fXmad8zTY851J3pXkN7OPD3f3g8uudV5Get6wt5KcSHJ3d39weVXO12jPVfWOJHcm2ZP16/sN3f2LZdY6L4PX9nVJ/j7r71z37CT/muQvuvs3Sy73klXVJ5L8aZL9SV7a3f95kT1TnF9T7NnMNrN3HTN7fjN72Xee70lypLsPJDmS5OhF9rw7yQuTvCjJrUnuqqr9S6tw/kZ6/kaSW7r7ZUnem+T+qrp6iTXO20jP5y/ao0keWGJti7Jpz7OXCLsryW3d/ZIkr0ry5DKLnLORn/OHk/xXd9+c5KVJ/jDJnyyvxLl6IMlr8tvfSGSK82uKPZvZu5+ZbWYn25xfSwvPs99mDiY5Nls6luTg7MX5N3pnknu7+9zsRf0fSPL2ZdU5T6M9d/eD3f2r2cPvZP033JWlFTpHW/g5J8mHknw1yckllbcQW+j5A0k+0d0/T5LufrK7f728SudnCz2vJbm2qvYm+Z2s38l4bGmFzlF3f627L3yXvgtNbn5lgj2b2Wb2bmNmP6Ntza9l3nm+Kclj3X02SWafH5+tb3ThW8Q+cpE9u8VozxvdnuSH3f3TJdS3CEM9V9XNSd6U5G+WXuH8jf6cX5zkD6rq36rqW1X1l1W1Z8m1zstozx9LciDJz5L8PMmD3f3vyyx0yaY4v6bY80Zm9u5jZpvZ521rfnnC4GWkql6b9Qv30GZ7d7OqelaSe5Pccf4f8kRcleTmJLcleW2SP0rynh2taPHenvU7c9cnuTHJa6rqbTtbEsyHmX3FM7PN7ItaZnh+NMmNszNT589O3TBb3+iRJM/f8Ph5F9mzW4z2nKq6Ncnnkry1u3upVc7XSM/XJ3lBkuNV9eMk70/yvqr61HJLnZvRn/NPknypu5/u7qeSfCXJK5Za6fyM9nw4yT/O/iT2ZNZ7ft1SK12uKc6vKfZsZpvZu42ZfXHbml9LC8/d/USSh/K/v6EfSnJidsZkoy9m/R/l3tlZnLcm+fKy6pyn0Z6r6pYk9yd5W3d/a7lVztdIz939SHc/t7v3d/f+JH+b9TNHf770gudgC9f255O8sar2zO7kvD7Jt5dX6fxsoecfZf1ZzKmqZyd5Q5L/94znK8jk5lcm2LOZbWbvNmb2M9rW/Fr2sY07khyuqpNZ/+3mjiSpquOzZ7UmyWeTPJzkVJKvJ/lodz+85DrnaaTnu5NcneRoVT00+3jpzpQ7FyM9X2lGev5CkieSfD/rQ+x7ST6zA7XOy0jP70/y6qr6btZ7Ppn1P//uOlX1yar6aZLfS/IvVfW92frU59cUezazdz8z28xOtjm/9qytrS2obAAAuLJ4wiAAAAwSngEAYJDwDAAAg4RnAAAYJDwDAMAg4RkAAAYJzwAAMEh4BgCAQf8D/6b+8JuiCykAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 864x1296 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run metrics visualization for the three supervised learning models chosen\n",
    "\n",
    "# Create figure\n",
    "fig, ax = plt.subplots(3, 2, figsize = (12,18))\n",
    "\n",
    "# Constants\n",
    "bar_width = 0.2\n",
    "colors =  ['#ff9408', '#3b638c', '#fe46a5', '#90b134']\n",
    "\n",
    "# Super loop to plot four panels of data\n",
    "for k, learner in enumerate(results.keys()):\n",
    "    for j, metric in enumerate(['train_time','pred_time', 'acc_train', 'acc_test', 'f_train', 'f_test']):\n",
    "        for i in np.arange(3):\n",
    "                \n",
    "            # Creative plot code\n",
    "            ax[j//2, j%2].bar(i+k*bar_width, results[learner][i][metric], width = bar_width, color = colors[k])\n",
    "            ax[j//2, j%2].set_xticks([0.45, 1.45, 2.45])\n",
    "            ax[j//2, j%2].set_xticklabels([\"1%\", \"10%\", \"100%\"])\n",
    "            ax[j//2, j%2].set_xlabel(\"Training Set Size\")\n",
    "            ax[j//2, j%2].set_xlim((-0.1, 3.0))\n",
    "    \n",
    "# Add y-labels\n",
    "ax[0, 0].set_ylabel(\"Time (in seconds)\")\n",
    "ax[0, 1].set_ylabel(\"Time (in seconds)\" )\n",
    "ax[1, 0].set_ylabel(\"Accuracy Score\")\n",
    "ax[1, 1].set_ylabel(\"Accuracy Score\")\n",
    "ax[2, 0].set_ylabel(\"F-score\")\n",
    "ax[2, 1].set_ylabel(\"F-score\")\n",
    "    \n",
    "# Add titles\n",
    "ax[0, 0].set_title(\"Model Training Time\")\n",
    "ax[0, 1].set_title(\"Model Predicting Time\")\n",
    "ax[1, 0].set_title(\"Accuracy Score on Training Set\")\n",
    "ax[1, 1].set_title(\"Accuracy Score on Testing Set\")\n",
    "ax[2, 0].set_title(\"F-score on Training Set\")\n",
    "ax[2, 1].set_title(\"F-score on Testing Set\")\n",
    "    \n",
    "# Add horizontal lines for naive predictors\n",
    "ax[1, 0].axhline(y = accuracy, xmin = -0.1, xmax = 3.0, linewidth = 1, color = 'k', linestyle = 'dashed')\n",
    "ax[1, 1].axhline(y = accuracy, xmin = -0.1, xmax = 3.0, linewidth = 1, color = 'k', linestyle = 'dashed')\n",
    "ax[2, 0].axhline(y = fscore, xmin = -0.1, xmax = 3.0, linewidth = 1, color = 'k', linestyle = 'dashed')\n",
    "ax[2, 1].axhline(y = fscore, xmin = -0.1, xmax = 3.0, linewidth = 1, color = 'k', linestyle = 'dashed')\n",
    "    \n",
    "# Set y-limits for score panels\n",
    "ax[1, 0].set_ylim((0, 1))\n",
    "ax[1, 1].set_ylim((0, 1))\n",
    "ax[2, 0].set_ylim((0, 1))\n",
    "ax[2, 1].set_ylim((0, 1))\n",
    "\n",
    "# Create patches for the legend\n",
    "patches = []\n",
    "for i, learner in enumerate(results.keys()):\n",
    "    patches.append(mpatches.Patch(color = colors[i], label = learner))\n",
    "plt.legend(handles = patches, bbox_to_anchor = (-0.08, 3.68), \\\n",
    "            loc = 'upper center', borderaxespad = 0., ncol = 2, fontsize = 'x-large')\n",
    "    \n",
    "# Aesthetics\n",
    "plt.suptitle(\"Performance Metrics for Three Supervised Learning Models\", fontsize = 16, y = 0.96)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving Results\n",
    "In this section, I will choose from the four supervised learning models the *best* model to use on the test data. I will then perform a grid search optimization for the model over the entire training set (`X_train` and `y_train`) to improve upon the untuned model's F-score. \n",
    "\n",
    "According to the model performance graph above, although the Random Forest performs best on training set but the AdaBoost Classifier finally predicts best on testing data. Although the accuracy of AdaBoost Classifier is quiet similar to the performance of other models, F-score of AdaBoost is better on both training and testing data when the model is applied to the whole data set. Also, in contrast to Support Vector Classfier which takes dramatically more time to train and predict, the AdaBoost is faster. In terms of binary classification, AdaBoost will also performs good in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Tuning\n",
    "Fine tune the chosen model. Use grid search (`GridSearchCV`). Use the entire training set for this. The code cell below will implement the following:\n",
    "- Initialize the classifier I've chosen and store it in `clf`.\n",
    "- Create a dictionary of parameters to tune for the chosen model.\n",
    "    - `n_estimators` and `learning_rate` of AdaBoostClassifier\n",
    "    - `max_depth` and `min_samples_split` of base_estimator\n",
    "- Use `make_scorer` to create an `fbeta_score` scoring object (with $\\beta = 0.5$).\n",
    "- Perform grid search on the classifier `clf` using the `'scorer'`, and store it in `grid_obj`.\n",
    "- Fit the grid search object to the training data (`X_train`, `y_train`), and store it in `grid_fit`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-81d69a8837dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Fit the grid search object to the training data and find the optimal parameters using fit()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mgrid_fit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Get the estimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Initialize the classifier\n",
    "clf = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(), random_state=42)\n",
    "\n",
    "# Create the parameters list \n",
    "parameters = {'n_estimators':[50,75,100,200], \n",
    "              'learning_rate':[0.05,0.1,0.3,1], \n",
    "              'base_estimator__min_samples_split' : np.arange(2, 8, 2),\n",
    "              'base_estimator__max_depth' : np.arange(1, 4, 1)}\n",
    "\n",
    "# Make an fbeta_score scoring object using make_scorer()\n",
    "scorer = make_scorer(fbeta_score, beta = 0.5)\n",
    "\n",
    "# Perform grid search on the classifier using 'scorer' as the scoring method using GridSearchCV()\n",
    "grid_obj = GridSearchCV(clf, parameters, scoring=scorer)\n",
    "\n",
    "start = time()\n",
    "# Fit the grid search object to the training data and find the optimal parameters using fit()\n",
    "grid_fit = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "# Get the estimator\n",
    "best_clf = grid_fit.best_estimator_\n",
    "\n",
    "# Make predictions using the unoptimized and model\n",
    "predictions = (clf.fit(X_train, y_train)).predict(X_test)\n",
    "best_predictions = best_clf.predict(X_test)\n",
    "end = time()\n",
    "\n",
    "# Report the before-and-afterscores\n",
    "print(\"Unoptimized model\\n------\")\n",
    "print(\"Accuracy score on testing data: {:.4f}\".format(accuracy_score(y_test, predictions)))\n",
    "print(\"F-score on testing data: {:.4f}\".format(fbeta_score(y_test, predictions, beta = 0.5)))\n",
    "print(\"\\nOptimized Model\\n------\")\n",
    "print(\"Final accuracy score on the testing data: {:.4f}\".format(accuracy_score(y_test, best_predictions)))\n",
    "print(\"Final F-score on the testing data: {:.4f}\".format(fbeta_score(y_test, best_predictions, beta = 0.5)))\n",
    "\n",
    "print(\"--- Run time: %s mins ---\" % np.round(((end - start)/60),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-b3f07dcad5f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_clf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'best_clf' is not defined"
     ]
    }
   ],
   "source": [
    "print(best_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model Evaluation\n",
    "\n",
    "|     Metric     |  Benchmark Model  |Unoptimized Model | Optimized Model |\n",
    "| :------------: | :---------------: |:---------------: | :-------------: | \n",
    "| Accuracy Score |      0.2478       |      0.8280      |     0.8701      |\n",
    "| F-score        |      0.2917       |      0.6518      |     0.7518      |\n",
    "\n",
    "The optimized model's accuracy on testing data is 0.8701 and F-score is 0.7518. Both of those scores are better than the unoptimized model. Also, the optimized model performs much better than the benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance\n",
    "\n",
    "Generally, it's useful to know which features provide the most predictive power when performing supervised learning on a dataset like the census data here. In this case, it means we wish to identify a small number of features that most strongly predict whether an individual makes at most or more than \\$50,000.\n",
    "\n",
    "Here will choose a scikit-learn classifier (e.g., adaboost, random forests) that has a `feature_importance_` attribute. Fit this classifier to training set and use this attribute to determine the top 5 most important features for the census dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Feature Importance\n",
    "\n",
    "The code cell below will implement the following:\n",
    " - Train the supervised model on the entire training set.\n",
    " - Extract the feature importances using `'.feature_importances_'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-98c6ab1b6739>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train the supervised model on the training set using .fit(X_train, y_train)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdaBoostClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Extract the feature importances using .feature_importances_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mimportances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Train the supervised model on the training set using .fit(X_train, y_train)\n",
    "model = AdaBoostClassifier(random_state=42).fit(X_train, y_train)\n",
    "\n",
    "# Extract the feature importances using .feature_importances_ \n",
    "importances = model.feature_importances_\n",
    "\n",
    "# Display the five most important features\n",
    "indices = np.argsort(importances)[::-1]\n",
    "columns = X_train.columns.values[indices[:5]]\n",
    "values = importances[indices][:5]\n",
    "\n",
    "# Creat the plot\n",
    "fig = plt.figure(figsize = (7,5))\n",
    "plt.title(\"Normalized Weights for First Five Most Predictive Features\", fontsize = 16)\n",
    "plt.bar(np.arange(5), values, width = 0.6, align=\"center\", color = '#00A000', label = \"Feature Weight\")\n",
    "plt.bar(np.arange(5) - 0.3, np.cumsum(values), width = 0.2, align = \"center\", color = '#00A0A0', \\\n",
    "        label = \"Cumulative Feature Weight\")\n",
    "plt.xticks(np.arange(5), columns)\n",
    "plt.xlim((-0.5, 4.5))\n",
    "plt.ylabel(\"Weight\", fontsize = 12)\n",
    "plt.xlabel(\"Feature\", fontsize = 12)\n",
    "    \n",
    "plt.legend(loc = 'upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the result, the featuer importance put 'capital-loss' the most important feature. It's probably because the bigger capital loss means that the person has to have that volume of money to invest. The 'age' ranks the second one which may because the elder the people the more salary they will have to donor. The 'hours-per-week' and 'sex_Female' ranks the forth and fifth which probably because it's not that sure cases. It's true since maybe the person works longer but have lower unit salary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection\n",
    "\n",
    "From the visualization above, we see that the top five most important features contribute more than half of the importance of **all** features present in the data. This hints that we can attempt to *reduce the feature space* and simplify the information required for the model to learn. The code cell below will use the same optimized model found earlier, and train it on the same training set *with only the top five important features*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-f04904c3a409>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Reduce the feature space\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mX_train_reduced\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimportances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mX_test_reduced\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimportances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Import functionality for cloning a model\n",
    "from sklearn.base import clone\n",
    "\n",
    "# Reduce the feature space\n",
    "X_train_reduced = X_train[X_train.columns.values[(np.argsort(importances)[::-1])[:5]]]\n",
    "X_test_reduced = X_test[X_test.columns.values[(np.argsort(importances)[::-1])[:5]]]\n",
    "\n",
    "# Train on the \"best\" model found from grid search earlier\n",
    "clf = (clone(best_clf)).fit(X_train_reduced, y_train)\n",
    "\n",
    "# Make new predictions\n",
    "reduced_predictions = clf.predict(X_test_reduced)\n",
    "\n",
    "# Report scores from the final model using both versions of data\n",
    "print(\"Final Model trained on full data\\n------\")\n",
    "print(\"Accuracy on testing data: {:.4f}\".format(accuracy_score(y_test, best_predictions)))\n",
    "print(\"F-score on testing data: {:.4f}\".format(fbeta_score(y_test, best_predictions, beta = 0.5)))\n",
    "print(\"\\nFinal Model trained on reduced data\\n------\")\n",
    "print(\"Accuracy on testing data: {:.4f}\".format(accuracy_score(y_test, reduced_predictions)))\n",
    "print(\"F-score on testing data: {:.4f}\".format(fbeta_score(y_test, reduced_predictions, beta = 0.5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As result above show, the model performs a bit worse if I only used important features. The accuracy is 5% lower and the f-score is 7% lower, so in this case I'll still choose to use all feature to build the model unless when the time for fitting model matters a lot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised clustering\n",
    "After I build the model predicting whether the individual has the income >50K, I'm gonna try to use unsupervised learning to cluster the population into groups. And see if I could get any insight from the clusters. Since in this case we don't need test data, I'll combine train and test to train clustering model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Feature Scaling\n",
    "\n",
    "Before we apply __dimensionality reduction techniques__ to the data, we need to perform __feature scaling__ so that the __principal component vectors are not influenced by the natural differences in scale for features.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'adult_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-7e7761aff4e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfeature_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madult_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'income'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfeatures_log_transformed_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfeatures_log_transformed_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mskewed\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mskewed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Initialize a scaler, then apply it to the features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'adult_data' is not defined"
     ]
    }
   ],
   "source": [
    "feature_all = adult_data.drop('income', axis=1)\n",
    "features_log_transformed_all = pd.DataFrame(data=feature_all)\n",
    "features_log_transformed_all[skewed] = feature_all[skewed].apply(lambda x: np.log(x + 1))\n",
    "\n",
    "# Initialize a scaler, then apply it to the features\n",
    "scaler = MinMaxScaler() # default=(0, 1)\n",
    "\n",
    "features_log_minmax_transform_all = pd.DataFrame(data = features_log_transformed_all)\n",
    "features_log_minmax_transform_all[num_col] = scaler.fit_transform(features_log_transformed_all[num_col])\n",
    "\n",
    "# Apply OHE above to transform the test dataset\n",
    "encoded_cat_feats_all = encoder.transform(features_log_minmax_transform_all.loc[:,cat_feats])\n",
    "\n",
    "# Generate OHE dataframe and concatenate it with the numerical dataframe later\n",
    "encoded_cat_feats_df_all = pd.DataFrame(encoded_cat_feats_all, columns=encoded_cat_feats_name)\n",
    "\n",
    "# Extract the dataframe with only numerical features\n",
    "num_feats_df_all = features_log_minmax_transform_all[num_col].reset_index()\n",
    "\n",
    "# Concatenate numerical and encoded categorical features together\n",
    "adult_data_processed = pd.merge(num_feats_df_all, encoded_cat_feats_df_all, left_index=True, right_index=True)\\\n",
    "                        .drop('index', axis=1)\n",
    "\n",
    "# Encode the 'income_raw' to numerical values\n",
    "# y_train = income_raw.apply(lambda x: 1 if x == '>50K' else 0)\n",
    "\n",
    "print(\"{} total features after one-hot encoding.\".format(len(X_all.columns)))\n",
    "\n",
    "scaler2 = StandardScaler()\n",
    "adult_data_processed[X_train.columns] = scaler2.fit_transform(adult_data_processed[X_train.columns].as_matrix())\n",
    "adult_data_processed.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Dimensionality Reduction\n",
    "On scaled data, now ready to apply dimensionality reduction techniques.\n",
    "\n",
    "- Use sklearn's PCA class to apply principal component analysis on the data, thus finding the vectors of maximal variance in the data.\n",
    "- Check out the ratio of variance explained by each principal component as well as the cumulative variance explained. - Plot the cumulative or sequential values. Based on what I find, select a value for the number of transformed features I'll retain for the clustering part of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'adult_data_processed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-3a15837c4409>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Apply PCA to the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madult_data_processed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'adult_data_processed' is not defined"
     ]
    }
   ],
   "source": [
    "# Apply PCA to the data\n",
    "pca = PCA()\n",
    "model = pca.fit_transform(adult_data_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate the variance accounted for by each principal component.\n",
    "\n",
    "def plot_pc(pca):\n",
    "    '''\n",
    "    Creates a scree plot associated with the principal components \n",
    "    \n",
    "    INPUT: pca - the result of instantian of PCA in scikit learn\n",
    "            \n",
    "    OUTPUT: None\n",
    "    '''\n",
    "    num_components=len(pca.explained_variance_ratio_)\n",
    "    ind = np.arange(num_components)\n",
    "    vals = pca.explained_variance_ratio_\n",
    " \n",
    "    plt.figure(figsize=(18, 8))\n",
    "    ax = plt.subplot(111)\n",
    "    cumvals = np.cumsum(vals)\n",
    "    ax.bar(ind, vals)\n",
    "    ax.plot(ind, cumvals)\n",
    "    for i in range(num_components):\n",
    "        ax.annotate(r\"%s%%\" % ((str(vals[i]*100)[:4])), (ind[i]+0.2, vals[i]), va=\"bottom\", ha=\"center\", fontsize=12)\n",
    " \n",
    "    ax.xaxis.set_tick_params(width=0)\n",
    "    ax.yaxis.set_tick_params(width=2, length=12)\n",
    " \n",
    "    ax.set_xlabel(\"Principal Component\")\n",
    "    ax.set_ylabel(\"Variance Explained (%)\")\n",
    "    plt.title('Explained Variance Per Principal Component')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PCA' object has no attribute 'explained_variance_ratio_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-4ae2bf776002>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_pc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpca\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-34-2cf638933c6e>\u001b[0m in \u001b[0;36mplot_pc\u001b[0;34m(pca)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mOUTPUT\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     '''\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mnum_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplained_variance_ratio_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_components\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplained_variance_ratio_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PCA' object has no attribute 'explained_variance_ratio_'"
     ]
    }
   ],
   "source": [
    "plot_pc(pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PCA' object has no attribute 'explained_variance_ratio_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-0c6d8373349c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Find appropriate number of components to retain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplained_variance_ratio_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     print('For {} components, explained variance:'.format(i), \n\u001b[1;32m      5\u001b[0m           pca.explained_variance_ratio_[:i].sum())\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PCA' object has no attribute 'explained_variance_ratio_'"
     ]
    }
   ],
   "source": [
    "# Find appropriate number of components to retain\n",
    "start = time()\n",
    "for i in np.arange(20, len(pca.explained_variance_ratio_), 3):\n",
    "    print('For {} components, explained variance:'.format(i), \n",
    "          pca.explained_variance_ratio_[:i].sum())\n",
    "end = time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'adult_data_processed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-c5b2bb91488a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpca_80\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madult_data_processed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'adult_data_processed' is not defined"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=80)\n",
    "pca_80 = pca.fit_transform(adult_data_processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpret Principal Components\n",
    "\n",
    "Now that we have our transformed principal components, it's a nice idea to check out the weight of each variable on the first few components to see if they can be interpreted in some fashion.\n",
    "\n",
    "- To investigate the features, map each weight to their corresponding feature name, then sort the features according to weight. The most interesting features for each principal component, then, will be those at the beginning and end of the sorted list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to show the weight of each features by dimension\n",
    "def show_weight(full_dataset, pca, comp_n, feat_n):\n",
    "    '''\n",
    "    Display the weight of each feature in dimension i\n",
    "    INPUT: \n",
    "        full_dataset: dataset\n",
    "        pca: PCA model fitted with data\n",
    "        comp_n: index of component\n",
    "        feat_n: feature number\n",
    "    OUTPUT: weight of each feature \n",
    "    '''\n",
    "    components = pd.DataFrame(np.round(pca.components_, 4), columns=full_dataset.keys()).iloc[comp_n - 1]\n",
    "    components.sort_values(ascending=False, inplace=True)\n",
    "    top2n_components = pd.concat([components.head(feat_n), components.tail(feat_n)])\n",
    "\n",
    "    # Plot the result\n",
    "    top2n_components.plot(kind='bar', \n",
    "                          title='Top {} weighted features for PCA component {}'.format(feat_n*2, comp_n),\n",
    "                          figsize=(12, 6))\n",
    "    plt.show()\n",
    "#     top_components = pd.concat([components.iloc[:5,:],components.iloc[-5:]]).reset_index()\n",
    "    return top2n_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'adult_data_processed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-86ca76acb894>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# and then print the linked values, sorted by weight.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcomponents1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshow_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madult_data_processed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mcomponents1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'adult_data_processed' is not defined"
     ]
    }
   ],
   "source": [
    "# Map weights for the first principal component to corresponding feature names\n",
    "# and then print the linked values, sorted by weight.\n",
    "\n",
    "components1 = show_weight(adult_data_processed, pca, 1, 5)\n",
    "components1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'adult_data_processed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-5c29eb306ffc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# and then print the linked values, sorted by weight.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcomponents2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshow_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madult_data_processed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mcomponents2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'adult_data_processed' is not defined"
     ]
    }
   ],
   "source": [
    "# Map weights for the second principal component to corresponding feature names\n",
    "# and then print the linked values, sorted by weight.\n",
    "\n",
    "components2 = show_weight(adult_data_processed, pca, 2, 5)\n",
    "components2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'adult_data_processed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-fb54793d97e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# and then print the linked values, sorted by weight.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcomponents3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshow_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madult_data_processed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mcomponents3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'adult_data_processed' is not defined"
     ]
    }
   ],
   "source": [
    "# Map weights for the third principal component to corresponding feature names\n",
    "# and then print the linked values, sorted by weight.\n",
    "\n",
    "components3 = show_weight(adult_data_processed, pca, 3, 5)\n",
    "components3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations from detailed investigation of the first few principal components generated. Can we interpret positive and negative values from them in a meaningful way?\n",
    "\n",
    "From the analysis above, it shows detail of how each feature distibute within each dimension. Analyse the first three dimensions along with top 10 features in details.\n",
    "\n",
    "#### Dimension 1\n",
    "- In the first dimension, it's positively affected by  \n",
    "    - sex_Female                              0.3330\n",
    "    - marital-status_Never-married            0.2760\n",
    "    - relationship_Own-child                  0.1861\n",
    "    - relationship_Not-in-family              0.1710\n",
    "    - relationship_Unmarried                  0.1546\n",
    "- In the first dimension, it's positively affected by  \n",
    "    - age                                    -0.1849\n",
    "    - hours-per-week                         -0.1864\n",
    "    - sex_Male                               -0.3330\n",
    "    - marital-status_Married-civ-spouse      -0.3984\n",
    "    - relationship_Husband                   -0.4160\n",
    "\n",
    "\n",
    "#### Dimension 2\n",
    "- In the second dimension, it's positively affected by   \n",
    "    - workclass_Private                    0.2139\n",
    "    - native-country_Mexico                0.1939\n",
    "    - sex_Male                             0.1930\n",
    "    - education_HS-grad                    0.1756\n",
    "    - occupation_Craft-repair              0.1601\n",
    "- In the second dimension, it's positively affected by  \n",
    "    - sex_Female                          -0.1930\n",
    "    - education_Masters                   -0.1939\n",
    "    - education_Bachelors                 -0.2301\n",
    "    - occupation_Prof-specialty           -0.2858\n",
    "    - education-num                       -0.4595\n",
    "\n",
    "#### Dimension 3\n",
    "- In the third dimension, it's positively affected by   \n",
    "    - race_Asian-Pac-Islander                 0.4008\n",
    "    - native-country_Philippines              0.2248\n",
    "    - race_Black                              0.1603\n",
    "    - native-country_India                    0.1562\n",
    "    - native-country_China                    0.1535\n",
    "- In the third dimension, it's positively affected by  \n",
    "    - workclass_Private                      -0.0902\n",
    "    - marital-status_Never-married           -0.1466\n",
    "    - relationship_Own-child                 -0.1615\n",
    "    - race_White                             -0.3682\n",
    "    - native-country_United-States           -0.4475"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Clustering\n",
    "We've assessed and cleaned the demographics data, then scaled and transformed them. Now, it's time to see how the data clusters in the principal components space. In this substep, I will apply k-means clustering to the dataset and use the average within-cluster distances from each point to their assigned cluster's centroid to decide on a number of clusters to keep.\n",
    "\n",
    "- Use sklearn's KMeans class to perform k-means clustering on the PCA-transformed data.\n",
    "- Then, compute the average difference from each point to its assigned cluster's center. \n",
    "- Perform the above two steps for a number of different cluster counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate the change in within-cluster distance across number of clusters.\n",
    "def get_kmeans_score(data, center):\n",
    "    '''\n",
    "    return the kmeans score regarding SSE for points to centers\n",
    "    INPUT:\n",
    "        data - the dataset you want to fit kmeans to\n",
    "        center - the number of centers you want\n",
    "    OUTPUT:\n",
    "        score - the SSE score for the kmeans model fit to the data\n",
    "    '''\n",
    "    # instantiate kmeans\n",
    "    kmeans = KMeans(n_clusters=center)\n",
    "    \n",
    "    # Then fit the model to you data using the fit mothod\n",
    "    model = kmeans.fit(data)\n",
    "    \n",
    "    # Obtain a score related to the model fit\n",
    "    score = np.abs(model.score(data))\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting k = 1 \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pca_80' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-62ec8f84ca14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcenter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcenters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Fitting k = {} '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcenter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_kmeans_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpca_80\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcenter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pca_80' is not defined"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "centers = list(range(1, 12))\n",
    "\n",
    "start = time()\n",
    "\n",
    "for center in centers:\n",
    "    print('Fitting k = {} '.format(center))\n",
    "    scores.append(get_kmeans_score(pca_80, center))\n",
    "end = time()\n",
    "\n",
    "print(\"--- Run time: %s mins ---\" % np.round(((end - start)/60),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (11,) and (0,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-0e2604fca28f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Plot the SSE value to decide the K value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcenters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinestyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'--'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'o'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'b'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'K'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'SSE'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'SSE vs. K'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2809\u001b[0m     return gca().plot(\n\u001b[1;32m   2810\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[0;32m-> 2811\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1808\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1810\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1812\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_alias_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1611\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1612\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m             \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_grab_next_args\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    391\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'plot'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             raise ValueError(\"x and y must have same first dimension, but \"\n\u001b[0;32m--> 231\u001b[0;31m                              \"have shapes {} and {}\".format(x.shape, y.shape))\n\u001b[0m\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             raise ValueError(\"x and y can be no greater than 2-D, but have \"\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (11,) and (0,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the SSE value to decide the K value\n",
    "plt.plot(centers, scores, linestyle='--', marker='o', color='b')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('SSE')\n",
    "plt.title('SSE vs. K')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pca_80' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-75e701c2edeb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# cluster predictions for the general population demographics data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mkmeans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkmeans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpca_80\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pca_80' is not defined"
     ]
    }
   ],
   "source": [
    "# Re-fit the k-means model with the selected number of clusters and obtain\n",
    "# cluster predictions for the general population demographics data.\n",
    "kmeans = KMeans(n_clusters=2)\n",
    "model = kmeans.fit(pca_80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try different K value range from 6 to 30, store SSE and compare to decide the final K value. As shown in plot above, there's no clear elbow, here choose 6 as cluster number since there's a relatively dramatice decrease at that point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-3ac8e41b0782>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Store the prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0madult_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpca_80\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Prediction'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Count the cluster number\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcluster_cnt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madult_predict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Prediction'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Store the prediction\n",
    "adult_predict = pd.DataFrame(np.array(model.predict(pca_80)), columns=['Prediction'])\n",
    "\n",
    "# Count the cluster number\n",
    "cluster_cnt = adult_predict['Prediction'].value_counts().sort_index()\n",
    "display(cluster_cnt)\n",
    "\n",
    "cluster_prop = pd.DataFrame((cluster_cnt/cluster_cnt.sum()), columns=['Prediction']).reset_index()\n",
    "cluster_prop.set_index('index', inplace=True)\n",
    "display(cluster_prop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cluster_prop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-810431401ed9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcluster_prop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcluster_prop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcluster_prop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'index'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Prediction'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'bar'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m18\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cluster Distribution'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cluster'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Proportion of persons in cluster'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cluster_prop' is not defined"
     ]
    }
   ],
   "source": [
    "cluster_prop = cluster_prop.reset_index()\n",
    "cluster_prop.plot(x = 'index', y = 'Prediction', kind = 'bar', figsize = (18,8 ))\n",
    "plt.title('Cluster Distribution')\n",
    "plt.xlabel('Cluster')\n",
    "plt.ylabel('Proportion of persons in cluster')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'KMeans' object has no attribute 'cluster_centers_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-e38abce53791>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Investigate top components of cluster 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcluster0_components\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkmeans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_centers_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcluster0_components\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcluster0_components\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KMeans' object has no attribute 'cluster_centers_'"
     ]
    }
   ],
   "source": [
    "# Investigate top components of cluster 0\n",
    "cluster0_components = pd.Series(kmeans.cluster_centers_[0])\n",
    "cluster0_components.sort_values(ascending=False, inplace=True)\n",
    "cluster0_components.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scaler2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-222a1669ef3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# To get the detail of cluster, transfer cluster back to analyze the principle component\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcluster0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpca_80\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0madult_predict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPrediction\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcluster0_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0madult_data_processed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# cluster0_features.head()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'scaler2' is not defined"
     ]
    }
   ],
   "source": [
    "# To get the detail of cluster, transfer cluster back to analyze the principle component\n",
    "cluster0 = scaler2.inverse_transform(pca.inverse_transform(pca_80))[adult_predict.Prediction==0]\n",
    "cluster0_features = pd.DataFrame(data = np.round(cluster0), columns= adult_data_processed.columns)\n",
    "# cluster0_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cluster0_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-342a2a4accc9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Chenck top features in first component\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mshow_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster0_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'cluster0_features' is not defined"
     ]
    }
   ],
   "source": [
    "# Chenck top features in first component\n",
    "show_weight(cluster0_features, pca, 1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cluster0_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-e2a1484bdf62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Chenck top features in first component\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mshow_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster0_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'cluster0_features' is not defined"
     ]
    }
   ],
   "source": [
    "# Chenck top features in first component\n",
    "show_weight(cluster0_features, pca, 5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'KMeans' object has no attribute 'cluster_centers_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-df9189b6e73f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Investigate top components of cluster 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcluster1_components\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkmeans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_centers_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcluster1_components\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcluster1_components\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KMeans' object has no attribute 'cluster_centers_'"
     ]
    }
   ],
   "source": [
    "# Investigate top components of cluster 1\n",
    "cluster1_components = pd.Series(kmeans.cluster_centers_[1])\n",
    "cluster1_components.sort_values(ascending=False, inplace=True)\n",
    "cluster1_components.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scaler2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-85c09a4e2cdf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# To get the detail of cluster, transfer cluster back to analyze the principle component\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcluster1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpca_80\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0madult_predict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPrediction\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcluster1_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0madult_data_processed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# cluster1_features.head()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'scaler2' is not defined"
     ]
    }
   ],
   "source": [
    "# To get the detail of cluster, transfer cluster back to analyze the principle component\n",
    "cluster1 = scaler2.inverse_transform(pca.inverse_transform(pca_80))[adult_predict.Prediction==1]\n",
    "cluster1_features = pd.DataFrame(data = np.round(cluster1), columns= adult_data_processed.columns)\n",
    "# cluster1_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cluster1_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-5da1aca64f57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Chenck top features in top component\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mshow_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster1_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'cluster1_features' is not defined"
     ]
    }
   ],
   "source": [
    "# Chenck top features in top component\n",
    "show_weight(cluster1_features, pca, 0, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cluster1_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-217e374dde1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Chenck top features in top component\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mshow_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster1_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'cluster1_features' is not defined"
     ]
    }
   ],
   "source": [
    "# Chenck top features in top component\n",
    "show_weight(cluster1_features, pca, 4, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
